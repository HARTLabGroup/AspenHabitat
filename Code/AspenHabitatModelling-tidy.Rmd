---
title: "Title"
author: "Sarah J. Hart, Asha Paudel..."
email: "Hart: Sarah.Hart@colostate.edu"
date: "Sept 20, 2023"
output: 
  bookdown::word_document2:
    reference_docx: Template.docx
    fig_caption: yes
    toc: no
    number_sections: no
    df_print: kable
editor_options: 
  chunk_output_type: inline
bibliography: references.bib
csl: "`r here:::here('forest-ecology-and-management.csl')`"
link-citations: true
urlcolor: blue
linkcolor: blue
citationcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
	message = FALSE,
	warning = FALSE,
	progress = FALSE,
	cache = FALSE,
	dpi = 300
)

set.seed(513)
options(repos = c(CRAN = "http://cran.rstudio.com"))
options(timeout=60*30) #timeout downloads that last longer than 30 minutes


if (!require("pacman")) install.packages("pacman")
pacman::p_load(
  devtools,
  knitr, # markdown documents
  flextable, # plot tables
  bookdown, # figure numbering in markdown
  here, # easy file structure
  tidyverse, # data manipulation
  ggplot2, # figures
  patchwork, # multiple figures
  grid, # multiple figures
  gridExtra,
  ggsci, # color palettes
  colorspace, # color palettes
  RColorBrewer, # color palettes
  ggcorrplot, # plot correlation between variables
  sf, # spatial data (new pkg)
  terra, # raster data
  rgdal,
  raster, # (old pkg)
  rasterVis,
  tidyterra, #tidyverse extension to spatial data
  tmap, # easy plotting of maps
  terrainr, # elevation data
  spatialEco, # hli, tpi
  readxl, # read in excel data
  parallel,
  FNN,
  maptools,
  rgeos,
  elevatr, 
  tidymodels,
  vip,
  DALEXtra,
  ncf, #spline correlog
  probably, 
  spatialsample, # spatial sampling
  spatialRF
) 
terraOptions(progress=0) # suppress all progress bars in terra
cores <- parallel::detectCores() # Set number of cores for parallel processing

# Set custom plotting theme
theme_new <- function(base_size = 9,base_family = "Helvetica"){
  theme_classic(base_size = base_size, base_family = base_family) %+replace%
    theme(
      axis.line.x = element_line(color="black", linewidth = 0.25),
      axis.line.y = element_line(color="black", linewidth = 0.25),
      axis.title = element_text(size = 9),
      axis.text = element_text(colour="black", size=8),
      legend.key=element_rect(colour=NA, fill =NA),
      panel.grid = element_blank(),   
      plot.background = element_rect(fill = NA, colour = NA),
      panel.border = element_rect(fill = NA, colour = NA),
      panel.background = element_rect(fill = "white", colour = "black"), 
      strip.background = element_rect(fill = "white"),
      strip.text = element_text(size = 9)
      
    )
}
theme_set(theme_new())

set_flextable_defaults(
  font.family="Times", 
  font.size=12,
  line_spacing=1,
  padding.bottom=1,
  padding.top=1,
  text.align='center')



# Set directory structure for project
dir.create(here("Data"), showWarnings = FALSE)
dir.create(here("Data", "Spatial"), showWarnings = FALSE)
dir.create(here("Data", "Spatial", "Predictions"), showWarnings = FALSE)
dir.create(here("Results"), showWarnings = FALSE)
dir.create(here("Results", "Figures"), showWarnings = FALSE)
```

# Abstract

# Highlights

-   Across the SRM,

-   

# Introduction

1.  Climate change, species distribution, and adaptive management
2.  Integration of species distribution models and remote sensing
    -   Species distribution models (SDMs) have been widely used to identify suitable habitats (REF) and predict species range shifts (REF) and inform management practices (REF).

    -   Most of the published SDMs use species occurrence data from herbaria, species atlases, field surveys, expert range maps, and citizen science, but lack [@he2015WillRemoteSensing], however most of these datasets lack information on species absence.

    -   More recently data from remote sensing have been used to produce SDMs [@bradley2006CharacterizingLandscapeDynamics]. Remotely sensed maps of species precence and absence offer several advantages, relative to traditional species occurrence data, Notably, species distribution maps produced by remote sensing methods exhibit less spatial bias and provided information on species absences [@he2015WillRemoteSensing].

    -   Remotely sensed spatially continuous data products can allow for more robust assessments of future range shifts by incorporating locations of known populations and information on dispersal distances.
3.  Why aspen
    -   widely distributed
    -   biodiversity & other ecosystem services
4.  Study objectives
    -   Specifically our objectives are to: (1) better understand the relationships between aspen presence and climate, topographic, and edaphic factors and (2) map the area suitable for aspen under current climate conditions, and (3) project areas where aspen may expand, contract, or remain stable.
    -   Differences from previous research

# Materials and Methods

## Study area

The study area consists of the Southern Rocky Mountains Ecoregion (SRME), an area of approximately 145,700 km^2^ that extends from southern Wyoming to northern New Mexico (Fig. \@ref(fig:StudyArea)). The SRME consists of rugged, topography with elevation ranging from 1450 m to above 4400 m, seven mountain ranges that largely trend north-south, and four Intermontane basins [@drummond2012SouthernRockiesEcoregion]. The climate of the SRME is characterized by a continental climate, with hot summers (mean July maximum temperature of 24.5°C) and cool winters (mean January minimum temperatures of -12.3°C), and moderate precipitation (mean annual precipitation of 625 mm), most of which falls as snow [@lukas2014ClimateChangeColorado; @rodman2021EffectsBarkBeetle]. At local scales, the climate is driven by elevation gradients, the prevailing westerly winds, and the north-south orientation of the mountains. Temperatures are warmer at lowerr elevations, while more precipitation falls at higher elevations, particularly on the windward side of the Rockies [@lukas2014ClimateChangeColorado]. Summer precipitation patterns exhibit a distinct latitudinal gradient, where more southern locations often receive more precipitation due to the North American Monsoon system [@lukas2014ClimateChangeColorado].

Ecosystems of the SRME correspond with topoclimatic patterns; low elevation valleys and intermountain basins are dominated by grasslands and shrublands, forest occupy intermediate elevations, while grasses, sedges, cushion plants, forbs, mosses, and lichens dominate cold, alpine elevations [@comer2001SouthernRockyMountains]. Within the ca. 55% of the SRME that is forested [@drummond2012SouthernRockiesEcoregion], tree communities also follow elevation gradients. Lower montane forests (\< 2,300 m) are generally composed of ponderosa pine (*Pinus ponderosae*) woodlands, piñon (*Pinus edulis*) and juniper (*Juniperus* spp.) woodlands, and gambel oak (*Quercus gambelii*) shrublands. Forests of the upper montane zone (ca. 2,300 - 2,800 m) are dominated by ponderosa pine-Douglas fir mixed conifer systems, quaking aspen, and lodgepole pine (*Pinus contorta*). Forests of the subalpine zone (ca. 2,800 m - 3,200 m) are dominated by Engelmann spruce, subalpine fir, and to a lesser limber pine (*Pinus flexilis)* and Rocky Mountain bristlecone pine (*P. aristata*). Forests dynamics across the SRME are strongly shaped by climate-sensitive disturbances, notably wildfires, outbreaks of native bark beetles, and windstorms [@peet1981ForestVegetationColorado; @baker1990; @veblen1994DisturbanceRegimeDisturbance; @veblen2000ClimaticHumanInfluences; @chapman2012SpatiotemporalPatternsMountain; @hart2014DroughtInducesSpruce).

```{r StudyArea, fig.cap="The Southern Rocky Mountain Ecoregion and current distribution of aspen."}
knitr::include_graphics(here("Results", "Figures", "StudyArea.jpg"), dpi=NA)
```

```{r DL_ecoregions}
temp <- here("Data", "Spatial", "Ecoregions","us_eco_l3.zip")
if(!file.exists(temp)){
download.file("https://gaftp.epa.gov/EPADataCommons/ORD/Ecoregions/us/us_eco_l3.zip", temp, mode="wb")
unzip(temp, exdir=here("Data", "Spatial", "Ecoregions"))
}
```

## Data

### Species occurrence data

To build SDMs, we used a 10-m gridded map of aspen presence-absence produced by Cook et al. [in review]. Briefly, this dataset was produced by xyz. The map represents the distribution of aspen in ca. XXXX and is characterized by an overall accuracy of XX. To generate our SDMs, we aggregated the data from 10-m to 90-m, a scale relevant to management [@rehfeldt2015].

```{r DL_aspen}
dir.create(here("Data", "Spatial", "Aspen"), showWarnings = FALSE)
temp <- here("Data", "Spatial", "Aspen", "SRM_ASPEN_CLASSIFIED_RF_10M_V1_0223.tif", mode="wb")
if(!file.exists(temp)){
download.file("https://1drv.ms/u/s!Aq4s9rj0qHBilL4B4PH1amvdUoiLyg?e=jHRUWI", temp )
}
```

### Predictor variables

To understand how climate is related to the contemporary distribution of aspen and the potential for future climate change to drive range shifts, we obtained gridded climate data from the AdaptWest Project [-@adaptwestproject2022GriddedCurrentProjected]. This dataset consists of both current and future climate data that are downscaled to 1 x 1 km resolution using the ClimateNA software (version 7.3) [@wang2016LocallyDownscaledSpatially] . Contemporary climate conditions, defined here as climatalogical norms for the 1981-2010 period, were generated from 4 x 4 km climate data provided by the PRISM Climate Group [-@prismclimategroup2021]. Future climate conditions were generated from data included in the sixth phase of Coupled Model Intercomparison Project (CMIP6). Here we used projections of future climate for the periods 2011-2040, 2041-2070, and 2071-2100. Given considerable uncertainty about future emissions, we compared two scenarios (i.e., Shared Socioeconomic Pathways; SSPs) generated under CMIP6, SSP2-4.5 and SSP5-8.5. The SSP2-4.5 scenario describes an intermediate scenario characterized by moderate increases in emissions through 2040 followed by a decline, while the SSP5-8.5 scenario describes a more extreme situation where emissions increase through 2100 [@riahi2017SharedSocioeconomicPathways]. In addition to uncertainty about societal decisions about greenhouse gas emissions represented in the SSPs, variation exists among the more than 50 atmosphere-ocean general circulation models (AOGCMs) included in CMIP6. Because of differences in complexity, assumptions, and parameterization of AOGCMS, not all forecasts are equally useful for regional planning purposes. Here we make use of an ensemble dataset constructed from eight AOCGMs identified by Mahony et al. [-@mahony2022GlobalClimateModel] as being appropriate for regional applications in North America, including species distribution modeling.

To characterize the climate space that aspen currently occupies, we examined 34 biologically-relevant climate variables commonly used in species distribution models (Table \@ref(tab:TabClimateScreen)). Broadly, these variables characterize the temperature, precipitation, seasonality, and interactions between precipitation and temperature. To avoid collinearity between climate predictors, we calculated pairwise correlation coefficients. When \|r\|\>0.75, we removed variables based on existing research (Table \@ref(tab:TabClimateScreen)). Where evidence was similar, we used univariate random forest (RF) models to evaluate the potential explanatory power of each predictor. The resulting dataset consisted of six climate variables: (1) an annual dryness index (ADI), (2) growing season precipitation (GSP), (3) the ratio of GSP to degree days above 5 °C (GSPDD5), (4) the ratio of GSP to mean annual precipitation (PRATIO), (5) mean annual relative humidity (RH), and (6) the difference between the mean coldest month temperature and the mean warmest month temperature (TD) (Table \@ref(tab:TabSelectedPredictors)).

Given mountainous areas such as the SRME are characterized high topoclimatic variation [@franklin2013ModelingPlantSpecies], we further downscaled our selected climate variables from a 1 km resolution to a 250 m resolution using gradient and inverse distance squared (GIDS) interpolation [@nalder1998SpatialInterpolationClimatic; @flint2012DownscalingFutureClimate], following methods outlined in Rodman et al. [-@rodman2020ChangingClimateSnuffing]. As ancillary data in the downscaling, we used a digital elevation model (DEM) from the USGS [-@u.s.geologicalsurvey2023USGS3DElevation].

In addition to climate variables, we also included data describing terrain and soils as predictors in our models. To account for the potential effects of local topographic variation on soil transport and water balance [@jones1985Soils], we used a 30-m DEM from the USGS [-@u.s.geologicalsurvey2023USGS3DElevation] to calculate the topographic position index [TPI; @weiss2001]. We calculated TPI for a 3-cell neighborhood (TPI3) to characterize fine scale topographic patterns [@rodman2020ChangingClimateSnuffing]. To account for the effects of aspect and slope on local climate, we calculated the Heat Load Index [HLI; @mccune2002EquationsPotentialAnnual; @mccune2007ImprovedEstimatesIncident]. Both HLI and TPI3 were calculated in R using the *spatialeco* package [@spatialEco]. Given soil properties may influence aspen demographic processes [@jones1985Soils], we obtained 30-m probabilistic maps of soil pH, the percentage of organic material, the percentage of clay, and saturated soil water content from the POLARIS database [@chaney2019POLARISSoilProperties]. We did not include elevation, latitude, and longitude as predictors in our modeling because we assumed these relationships were only correlative [@araujo2019StandardsDistributionModels]. We re-sampled soil and topographic predictors to a 90-m resolution by calculating the mean and projected the data to Universal Transmercator (UTM) Zone 13N to match the maps of aspen occurrence.

```{r TabSelectedPredictors}
pred.var.tab <- read_excel(here("Documents", "PredictorScreeningTable.xlsx"), sheet=2)

pred.var.tab %>% as.data.frame() %>% flextable()  %>% set_caption(caption="Predictor variables tested for inclusion in modelling and their hypothesized relationship with aspen's distirbution. Variables marked with an asterisk were removed prior to model building to reduce collinearity among predictors.") %>% autofit() %>% set_table_properties(layout = "autofit")
```

```{r DL_soils}
 #SRM <- st_read(here("Data", "Spatial", "Ecoregions","us_eco_l3.shp")) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs=4326) %>% st_bbox 
lons <- c("110-109", "109-108", "108-107", "107-106", "106-105", "105-104", "104-103")
lats <- c("3536", "3637", "3738", "3839","3940", "4041", "4142", "4243")

if(!file.exists(here("Data","Spatial", "Soils"))){
  dir.create(here("Data","Spatial", "Soils"), showWarnings = FALSE)

 
  # download mean pH of top 5-15 cm
  for(j in lons){
    for(k in lats){
      temp <- paste0(here("Data","Spatial", "Soils", "lat"), k,"_lon-", j, "_meanPh_5_15.tif")
      download.file(paste0("http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/ph/mean/5_15/lat",   k, "_lon-", j, ".tif"), temp, mode="wb")
    }
  }
  
  # Merge mean pH files
  ph.files <- list.files(path=here("Data","Spatial", "Soils"), pattern="meanPh_5_15.tif", full.names=T)
  ph.rast <- lapply(ph.files,FUN=rast)
  ph.rast <- sprc(ph.rast)
  ph.merge <- merge(ph.rast, first=T)
  writeRaster(ph.merge, here("Data","Spatial", "Soils", "meanPh_5_15-SRM.tif"))
  
  # download mean percent clay of top 5-15 cm
  for(j in lons){
    for(k in lats){
      temp <- paste0(here("Data","Spatial", "Soils", "lat"), k,"_lon-", j, "_meanClay_5_15.tif")
      download.file(paste0("http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/clay/mean/5_15/lat"  , k, "_lon-", j, ".tif"), temp, mode="wb")
    }
  }
  
  # Merge mean clay files
  clay.files <- list.files(path=here("Data", "Spatial", "Soils"), pattern="meanClay_5_15.tif",   full.names=T)
  clay.rast <- lapply(clay.files,FUN=rast)
  clay.rast <- sprc(clay.rast)
  clay.merge <- merge(clay.rast, first=T)
  writeRaster(clay.merge, here("Data", "Spatial", "Soils", "meanClay_5_15-SRM.tif"))

### download mean percent theta_s (saturated soil water content) of top 5-15 cm
  for(j in lons){
    for(k in lats){
      temp <- paste0(here("Data","Spatial", "Soils", "lat"), k,"_lon-", j, "_meantheta_s_5_15.tif")
      download.file(paste0("http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/theta_s/mean/5_15/lat"  , k, "_lon-", j, ".tif"), temp, mode="wb")
    }
  }
  
  # Merge theta_s files
  theta_s.files <- list.files(path=here("Data", "Spatial", "Soils"), pattern="meantheta_s_5_15.tif",   full.names=T)
  theta_s.rast <- lapply(theta_s.files,FUN=rast)
  theta_s.rast <- sprc(theta_s.rast)
  theta_s.merge <- merge(theta_s.rast, first=T)
  writeRaster(theta_s.merge, here("Data", "Spatial", "Soils", "meantheta_s_5_15-SRM.tif"),overwrite=T)
  
  ##download mean percent om (organic matter) of top 5-15 cm
  for(j in lons){
    for(k in lats){
      temp <- paste0(here("Data","Spatial", "Soils", "lat"), k,"_lon-", j, "_meanom_5_15.tif")
      download.file(paste0("http://hydrology.cee.duke.edu/POLARIS/PROPERTIES/v1.0/om/mean/5_15/lat"  , k, "_lon-", j, ".tif"), temp, mode="wb")
    }
  }
  
 # Merge om files
  om.files <- list.files(path=here("Data", "Spatial", "Soils"), pattern="meanom_5_15.tif",   full.names=T)
  om.rast <- lapply(om.files,FUN=rast)
  om.rast <- sprc(om.rast)
  om.merge <- merge(om.rast, first=T)
  writeRaster(om.merge, here("Data", "Spatial", "Soils", "meanom_5_15-SRM.tif"))
}
```

```{r DL_DEM}
if(!file.exists(here("Data", "Spatial","DEM"))){
  
  dir.create(here("Data", "Spatial","DEM"), showWarnings = FALSE)
  
  SRM <- st_read(here("Data", "Spatial", "Ecoregions",
"us_eco_l3.shp")) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs=5071) %>% st_buffer(20000)

  # 30 m 
  dem <- get_tiles(data=SRM, output_prefix = here("Data", "Spatial", "DEM", "DEM30"), services="elevation",   resolution=30)
dem.rast <- lapply(dem$elevation,FUN=rast)
  for(j in 2:length(dem.rast)){dem.rast[[j]] <-  terra::project(dem.rast[[j]], dem.rast[[1]], align=T)}
  dem.sprc <- sprc(dem.rast)
  dem.mosaic <- mosaic(dem.sprc)
  writeRaster(dem.mosaic, here("Data", "Spatial", "DEM", "DEM30-mosaic.tif"), overwrite=T)
  
 # 90 m 
  dem <- get_tiles(data=SRM, output_prefix = here("Data", "Spatial", "DEM", "DEM90"), services="elevation",   resolution=90)
dem.rast <- lapply(dem$elevation,FUN=rast)
  for(j in 2:length(dem.rast)){dem.rast[[j]] <-  terra::project(dem.rast[[j]], dem.rast[[1]], align=T)}
  dem.sprc <- sprc(dem.rast)
  dem.mosaic <- mosaic(dem.sprc)
  writeRaster(dem.mosaic, here("Data", "Spatial", "DEM", "DEM90-mosaic.tif"), overwrite=T)
   
  
  # 250 m 
  dem <- get_tiles(data=SRM, output_prefix = here("Data", "Spatial", "DEM", "DEM250"), services="elevation",   resolution=250)
  dem.rast <- lapply(dem$elevation,FUN=rast)
  writeRaster(dem.rast[[1]], here("Data", "Spatial", "DEM", "DEM250.tif"), overwrite=T)
}
```

```{r Calc_HLI, eval=F}
# Heat load index
if(!file.exists(here("Data","Spatial", "DEM", "DEM30-mosaic-HLI.tif"))){
  dem.mosaic <- rast(here(here("Data","Spatial", "DEM", "DEM30-mosaic.tif")))
  hli.rast <- hli(dem.mosaic, force.hemisphere = "northern")
  writeRaster(hli.rast, here("Data","Spatial", "DEM", "DEM30-mosaic-HLI.tif"))
}
```

```{r Calc_TPI3, eval=F}
# Topographic position index 3 cell neighborhood
if(!file.exists(here("Data","Spatial", "DEM", "DEM30-mosaic-TPI3.tif"))){
  dem.mosaic <- rast(here(here("Data","Spatial", "DEM", "DEM30-mosaic.tif")))
  tpi.rast <- tpi(dem.mosaic, scale=3)
  writeRaster(tpi.rast, here("Data","Spatial", "DEM", "DEM30-mosaic-TPI3.tif"))
}
```

```{r Calc_TPI15, eval=F}
# Topographic position index 15 cell neighborhood
if(!file.exists(here("Data","Spatial", "DEM", "DEM30-mosaic-TPI15.tif"))){
  dem.mosaic <- rast(here(here("Data","Spatial", "DEM", "DEM30-mosaic.tif")))
  tpi.rast <- tpi(dem.mosaic, scale=15)
  writeRaster(tpi.rast, here("Data","Spatial", "DEM", "DEM30-mosaic-TPI15.tif"))
}
```

```{r DL_climatedata, eval=F}
dir.create(here("Data","Spatial", "Climate"))
if(!file.exists(here("Data","Spatial", "Climate", "ClimateNA"))){
  dir.create(here("Data","Spatial", "Climate", "ClimateNA"), showWarnings = FALSE)
  
  # Climate normals
  ## Monthly variables
  temp <- here("Data","Spatial", "Climate", "ClimateNA", "Normal_1981_2010_monthly.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/normals/Normal_1981_2010_monthly.zip", temp, mode="wb")
  unzip(temp, exdir=here("Data", "Spatial", "Climate", "CLimateNA"))
  
  ## Bioclimatic variables
  temp <- here("Data","Spatial", "Climate", "ClimateNA", "Normal_1981_2010_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/normals/Normal_1981_2010_bioclim.zip", temp, mode="wb")
  unzip(temp, exdir=here("Data", "Spatial", "Climate", "CLimateNA"))
  
  ## 2011-2040 Emission Scenario SSP2-4.5
  temp <- here("Data","Spatial", "Climate", "ClimateNA","ensemble_8GCMs_ssp245_2011_2040_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp245_2011_2040_bioclim.zip", temp, mode="wb")
  unzip(temp, exdir=here("Data", "Spatial", "Climate", "CLimateNA"))
  
  ## 2040-2070 Emission Scenario SSP2-4.5
  temp <- here("Data","Spatial", "Climate", "ClimateNA","ensemble_8GCMs_ssp245_2041_2070_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp245_2041_2070_bioclim.zip", temp, mode="wb")
  unzip(temp, exdir=here("Data", "Spatial", "Climate", "CLimateNA"))
  
  ## 2071-2100 Emission Scenario SSP2-4.5
  temp <- here("Data","Spatial", "Climate", "ClimateNA","ensemble_8GCMs_ssp245_2071_2100_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp245_2071_2100_bioclim.zip", temp, mode="wb")
  unzip(temp, exdir=here("Data", "Spatial", "Climate", "CLimateNA"))
 
  ## 2011-2040 Emission Scenario SSP3-7.0
  temp <- here("Data/Spatial/Climate/CLimateNA/ensemble_8GCMs_ssp370_2011_2040_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp370_2011_2040_bioclim.zip", temp )
  unzip(temp, exdir=here("Data/Spatial/Climate/CLimateNA"))
  
  temp <- here("Data/Spatial/Climate/CLimateNA/ensemble_8GCMs_ssp370_2011_2040_monthly.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp370_2011_2040_monthly.zip", temp )
  unzip(temp, exdir=here("Data/Spatial/Climate/CLimateNA"))

  ## 2040-2070 Emission Scenario SSP3-7.0
  temp <- here("Data/Spatial/Climate/CLimateNA/ensemble_8GCMs_ssp370_2041_2070_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp370_2041_2070_bioclim.zip", temp )
  unzip(temp, exdir=here("Data/Spatial/Climate/CLimateNA"))
  
   temp <- here("Data/Spatial/Climate/CLimateNA/ensemble_8GCMs_ssp370_2041_2070_monthly.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp370_2041_2070_monthly.zip", temp )
  unzip(temp, exdir=here("Data/Spatial/Climate/CLimateNA"))

  ## 2071-2100 Emission Scenario SSP3-7.0
  temp <- here("Data/Spatial/Climate/CLimateNA/ensemble_8GCMs_ssp370_2071_2100_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp370_2071_2100_bioclim.zip", temp )
  unzip(temp, exdir=here("Data/Spatial/Climate/CLimateNA"))
  
  temp <- here("Data/Spatial/Climate/CLimateNA/ensemble_8GCMs_ssp370_2071_2100_monthly.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp370_2071_2100_monthly.zip", temp )
  unzip(temp, exdir=here("Data/Spatial/Climate/CLimateNA"))
  
   ##2011-2040 Emission Scenario SSP5-8.5
  temp <- here("Data","Spatial", "Climate", "ClimateNA","ensemble_8GCMs_ssp585_2011_2040_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp585_2011_2040_bioclim.zip", temp, mode="wb")
  unzip(temp, exdir=here("Data", "Spatial", "Climate", "CLimateNA"))
 
  ##2041-2070 Emission Scenario SSP5-8.5
  temp <- here("Data","Spatial", "Climate", "ClimateNA","ensemble_8GCMs_ssp585_2041_2070_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp585_2041_2070_bioclim.zip", temp, mode="wb")
  unzip(temp, exdir=here("Data", "Spatial", "Climate", "CLimateNA"))
  
  ##2071-2100 Emission Scenario SSP5-8.5
  temp <- here("Data","Spatial", "Climate", "ClimateNA","ensemble_8GCMs_ssp585_2071_2100_bioclim.zip")
  download.file("https://s3-us-west-2.amazonaws.com/www.cacpd.org/CMIP6v73/ensembles/ensemble_8GCMs_ssp585_2071_2100_bioclim.zip", temp, mode="wb")
  unzip(temp, exdir=here("Data", "Spatial", "Climate", "CLimateNA"))
}
```

```{r Calc_Derived_Climate_Variables, eval=F}
dir.create(here("Data", "Spatial", "Climate", "ClimateNA", "Derived"))
monthly.climate.rasters <- rast(list.files(here("Data", "Spatial", "Climate", "ClimateNA", "Normal_1981_2010/Normal_1981_2010_monthly"), full.names=T))

monthly.climate.rasters <- crop(monthly.climate.rasters, SRM)
names(monthly.climate.rasters) <- do.call(c, strsplit(sapply(strsplit(list.files(here("Data", "Spatial", "Climate", "ClimateNA", "Normal_1981_2010/Normal_1981_2010_monthly"), full.names=F), split="Normal_1981_2010_"), "[", 2), split=".tif"))

bioclimate.rasters <- rast(list.files(here("Data/Spatial/Climate/ClimateNA/Normal_1981_2010/Normal_1981_2010_bioclim"), pattern=".tif", full.names=T))
names(bioclimate.rasters) <- sapply(strsplit(do.call(c, strsplit(list.files(here("Data/Spatial/Climate/ClimateNA/Normal_1981_2010/Normal_1981_2010_bioclim"), pattern=".tif", full.names=F), split=".tif")), split="Normal_1981_2010_"), "[", 2)

SRM <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp")) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_buffer(5000) %>%  st_transform(crs(monthly.climate.rasters))
monthly.climate.rasters <- terra::crop(monthly.climate.rasters, SRM)
bioclimate.rasters <- terra::crop(bioclimate.rasters, SRM)

#ADI 
ADI <- (bioclimate.rasters[['DD5']]^0.5)/bioclimate.rasters[['MAP']]
writeRaster(ADI, filename=(here("Data", "Spatial", "Climate", "ClimateNA", "Derived", "Normal_1981_2010_ADI.tif")))

#GSP
GSP <- sum(monthly.climate.rasters[[paste0("PPT",c("04", "05", "06", "07","08","09"))]])
writeRaster(GSP, filename=(here("Data", "Spatial", "Climate", "ClimateNA", "Derived", "Normal_1981_2010_GSP.tif")))

#PRATIO
PRATIO <- GSP/bioclimate.rasters[["MAP"]]
writeRaster(PRATIO, filename=(here("Data", "Spatial", "Climate", "ClimateNA", "Derived", "Normal_1981_2010_PRATIO.tif")))

#GSPDD5
GSPDD5 <- GSP/bioclimate.rasters[["DD5"]]
writeRaster(GSPDD5, filename=(here("Data", "Spatial", "Climate", "ClimateNA", "Derived", "Normal_1981_2010_GSPDD5.tif")))

#TMAX 
TMAX <- max(monthly.climate.rasters[[paste0("Tmax",c("04", "05", "06", "07","08","09"))]])
writeRaster(TMAX, filename=(here("Data", "Spatial", "Climate", "ClimateNA", "Derived", "Normal_1981_2010_TMAX.tif")), overwrite=T)

select.scenarios<- c("ssp245", "ssp585")
select.years.all <- c("_2011_2040", "_2041_2070", "_2071_2100")
for(select.scenario in select.scenarios){
  
  for(select.year in select.years.all){
  monthly.climate.rasters <- rast(list.files(paste0(here("Data", "Spatial", "Climate", "ClimateNA"), "/ensemble_8GCMs_", select.scenario, select.year, "/ensemble_8GCMs_", select.scenario, select.year,"_monthly"), full.names=T))
  names(monthly.climate.rasters) <- sapply(strsplit(do.call(c,strsplit(list.files(paste0(here("Data", "Spatial", "Climate", "ClimateNA"), "/ensemble_8GCMs_", select.scenario, select.year, "/ensemble_8GCMs_", select.scenario, select.year,"_monthly"), full.names=F), split=".tif")),split=paste0("ensemble_8GCMs_", select.scenario, select.year, "_")), "[", 2)

 bioclimate.rasters <- rast(list.files(paste0(here("Data", "Spatial", "Climate", "ClimateNA"), "/ensemble_8GCMs_", select.scenario, select.year, "/ensemble_8GCMs_", select.scenario, select.year,"_bioclim"), full.names=T))
  names(bioclimate.rasters) <- sapply(strsplit(do.call(c,strsplit(list.files(paste0(here("Data", "Spatial", "Climate", "ClimateNA"), "/ensemble_8GCMs_", select.scenario, select.year, "/ensemble_8GCMs_", select.scenario, select.year,"_bioclim"), full.names=F), split=".tif")),split=paste0("ensemble_8GCMs_", select.scenario, select.year, "_")), "[", 2)
 
 SRM <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp")) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_buffer(5000) %>%  st_transform(crs(monthly.climate.rasters))

 monthly.climate.rasters <- crop(monthly.climate.rasters, SRM)
 bioclimate.rasters <- crop(bioclimate.rasters, monthly.climate.rasters)
 
 #ADI 
 ADI <- (bioclimate.rasters[['DD5']]^0.5)/bioclimate.rasters[['MAP']]
 writeRaster(ADI, filename=paste0(here("Data", "Spatial", "Climate", "ClimateNA", "Derived"), "/", select.scenario, select.year, "_ADI.tif"), overwrite=T)
 
 #GSP
 GSP <- sum(monthly.climate.rasters[[paste0("PPT",c("04", "05", "06", "07","08","09"))]])
 writeRaster(GSP, filename=paste0(here("Data", "Spatial", "Climate", "ClimateNA", "Derived"), "/", select.scenario, select.year, "_GSP.tif"), overwrite=T)
 
 #PRATIO
 PRATIO <- GSP/bioclimate.rasters[["MAP"]]
 writeRaster(PRATIO, filename=paste0(here("Data", "Spatial", "Climate", "ClimateNA", "Derived"), "/", select.scenario, select.year, "_PRATIO.tif"), overwrite=T)
 
 #GSPDD5
 GSPDD5 <- GSP/bioclimate.rasters[["DD5"]]
 writeRaster(GSPDD5, filename=paste0(here("Data", "Spatial", "Climate", "ClimateNA", "Derived"), "/", select.scenario, select.year, "_GSPDD5.tif"), overwrite=T)
  print(select.year)
  }
  print(select.scenario)
}
```

```{r Downscale}
source(here("Code", "GIDS-Downscaling-SJH.R"))
if(!dir.exists(here("Data", "Spatial", "Downscaled"))){
  # Set desired projection
  proj.proj <- "+proj=utm +zone=13 +ellps=GRS80 +datum=NAD83 +units=m +no_defs"
  
  # Import study area boundary
  study.area <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp")) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs(proj.proj)) %>% st_buffer(20000)
  
  # Import template for downscaling
  template <- rast(here("Data", "Spatial", "DEM", "DEM250.tif"))
  template <- template %>% terra::project(proj.proj)
  template<- template %>% crop(study.area)
    
  # Warning message happens because number of raster cells is not evenly divisible by number of cores on PC
  dir.create(here("Data", "Spatial", "Downscaled"), showWarnings = FALSE)
  select.climate.variables <-c( "DD_0", "MAR", "RH", "TD")
  select.derived.climate.variables <-c( "ADI", "PRATIO", "GSP")
  
  ### NORMALS
  for(j in select.climate.variables){
    if(!file.exists(paste0(here("Data", "Spatial", "Downscaled"), "/Normal_1981_2010_", j, "-downscaled.tif"))){
      ptm <- proc.time()
      clim <- rast(paste0(here("Data", "Spatial", "Climate", "CLimateNA", "Normal_1981_2010", "Normal_1981_2010_bioclim"), "/Normal_1981_2010_", j, ".tif"))
      clim <- clim %>% terra::project(proj.proj)
      clim <- clim %>% crop(study.area)
    
      template_coarse <- terra::project(template, clim, method="bilinear")

      
      ds_layer <- multiLevelInterpParrallel(boundary = study.area, ds_layer = clim,
                                          ancillary_list = list(template_coarse, template), 
                                          clip_dists = c(20000, 5000, 500))
    
      writeRaster(ds_layer, paste0(here("Data", "Spatial", "Downscaled"), "/Normal_1981_2010_", j, "-downscaled.tif"), overwrite=T)
      rm(ds_layer) # remove 
      gc() # clean up garbage (sometimes this helps)
      print(j) # print j so we know how far along our code is
      time <- proc.time() - ptm
      print(time[3]/60) # print time for each iteration 
    }
  
  }
  
  
  for(j in select.derived.climate.variables){
    if(!file.exists(paste0(here("Data", "Spatial", "Downscaled"), "/Normal_1981_2010_", j, "-downscaled.tif"))){
      ptm <- proc.time()
      clim <- rast(paste0(here("Data", "Spatial", "Climate", "CLimateNA", "Derived"), "/Normal_1981_2010_", j, ".tif"))
      clim <- clim %>% terra::project(proj.proj)
      clim <- clim %>% crop(study.area)
    
      template_coarse <- terra::project(template, clim, method="bilinear")
      
      ds_layer <- multiLevelInterpParrallel(boundary = study.area, ds_layer = clim,
                                          ancillary_list = list(template_coarse, template), 
                                          clip_dists = c(20000, 5000, 500))
    
      writeRaster(ds_layer, paste0(here("Data", "Spatial", "Downscaled"), "/Normal_1981_2010_", j, "-downscaled.tif"), overwrite=T)
      rm(ds_layer) # remove 
      gc() # clean up garbage (sometimes this helps)
      print(j) # print j so we know how far along our code is
      time <- proc.time() - ptm
      print(time[3]/60) # print time for each iteration 
    }
  
  }
  
  ## FUTURE
  select.scenarios<- c("ssp245", "ssp585")
  select.years.all <- c("_2011_2040", "_2041_2070", "_2071_2100")
  select.climate.variables <-c( "DD_0", "MAR", "TD")
  select.climate.variables <-"TD"
  select.derived.climate.variables <-c( "ADI", "PRATIO")
 
  
  for(select.scenario in select.scenarios){
    for(j in select.climate.variables){
      for(select.years in select.years.all){
        if(!file.exists(paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, select.years, "_", j, "-downscaled.tif"))){
          ptm <- proc.time()
          clim <- rast(paste0(here("Data", "Spatial", "Climate", "CLimateNA"), "/ensemble_8GCMs_", select.scenario, select.years, "/", "ensemble_8GCMs_", select.scenario, select.years, "_bioclim/", "ensemble_8GCMs_", select.scenario, select.years,"_", j, ".tif"))
          clim <- clim %>% terra::project(proj.proj)
          clim <- clim %>% crop(study.area)
      
          template_coarse <- terra::project(template ,clim, method="bilinear")
        
          ds_layer <- multiLevelInterpParrallel(boundary = study.area, ds_layer = clim,
                                            ancillary_list = list(template_coarse, template), 
                                            clip_dists = c(20000, 5000, 500))
      
          writeRaster(ds_layer, paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, select.years, "_", j, "-downscaled.tif"), overwrite=T)
          rm(clim)
          rm(ds_layer) # remove 
          rm(template_coarse)
          gc() # clean up garbage (sometimes this helps)
          time <- proc.time() - ptm
          print(paste(j, select.years, ":",time[3]/60)) # print time for each iteration
          
        }
      }
    }
  }
  
  for(select.scenario in select.scenarios){
    for(j in select.derived.climate.variables){
      for(select.years in select.years.all){
        if(!file.exists(paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, select.years,"_", j, "-downscaled.tif"))){
          ptm <- proc.time()
          clim <- rast(paste0(here("Data", "Spatial", "Climate", "CLimateNA", "Derived"), "/", select.scenario, select.years, "_", j,  ".tif"))
          clim <- clim %>% terra::project(proj.proj)
          clim <- clim %>% crop(study.area)
      
         template_coarse <- terra::project(template ,clim, method="bilinear")
        
          ds_layer <- multiLevelInterpParrallel(boundary = study.area, ds_layer = clim, ancillary_list = list(template_coarse, template), clip_dists = c(20000, 5000, 500))
      
         writeRaster(ds_layer, paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, select.years,"_", j, "-downscaled.tif"), overwrite=T)
         rm(clim) # remove 
         rm(ds_layer) # remove 
         gc() # clean up garbage (sometimes this helps)
         print(j) # print j so we know how far along our code is
         time <- proc.time() - ptm
         print(time[3]/60) # print time for each iteration 
        }
      }
    }
  }

  
}

```

```{r Resample}
if(!file.exists(here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic-90.tif"))){
  aspen <- rast(here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic.tif"))
  aspen90 <- aggregate(aspen, fact=9, fun="mean", cores=cores-1, filename=here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic-90.tif"),overwrite=T)
  
    aspen <- rast(here("Data", "Spatial", "Aspen", "srme_skcv_distribution_binopt.tif"))
  aspen90 <- aggregate(aspen, fact=9, fun="mean", cores=cores-1, filename=here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic-90.tif"),overwrite=T)

}


# soils
if(!file.exists(filename=here("Data", "Spatial", "Soils", "Soils90.tif"))){
  aspen90 <- rast(here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic-90.tif"))
  ph <- rast(here("Data", "Spatial", "Soils", "meanPh_5_15-SRM.tif"))  
  clay <- rast(here("Data", "Spatial", "Soils", "meanClay_5_15-SRM.tif"))
  om <- rast(here("Data", "Spatial", "Soils", "meanom_5_15-SRM.tif")) 
  theta_s <- rast(here("Data", "Spatial", "Soils", "meantheta_s_5_15-SRM.tif")) 
  soil <- c(ph, clay, om, theta_s) %>% terra::project(aspen90) %>% aggregate(fact=3, fun="mean",cores=cores-1)
  names(soil) <- c("pH", "clay", "om", "thetas")
  soil.re <- resample(soil, aspen90, method="near", threads=T, filefname=here("Data", "Spatial", "Soils", "Soils90.tif"), overwrite=TRUE)
}

#topographic data
if(!file.exists(filename=here("Data", "Spatial", "DEM", "Topo90.tif"))){
  aspen90 <- rast(here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic-90.tif"))
  tpi3 <- rast(here("Data", "Spatial", "DEM", "DEM30-mosaic-TPI3.tif")) 
  tpi15 <- rast(here("Data", "Spatial", "DEM", "DEM30-mosaic-TPI15.tif"))
  hli <- rast(here("Data", "Spatial", "DEM", "DEM30-mosaic-HLI.tif"))
  elev <- rast(here("Data", "Spatial", "DEM", "DEM30-mosaic.tif"))
  topo <- c(tpi3, tpi15, hli, elev) %>% terra::project(crs(aspen90)) %>% aggregate(fact=3, fun="mean",cores=cores-1)
  names(topo) <- c("tpi3", "tpi15", "hli", "elev")
  topo.re <- resample(topo, aspen90, method="average", threads=T, filename=here("Data", "Spatial", "DEM", "Topo90.tif"),overwrite=TRUE)
}

# historic climate data
if(!file.exists(filename=here("Data", "Spatial", "Downscaled", "Normals90.tif"))){
  aspen90 <- rast(here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic-90.tif"))
  climate <- rast(list.files(here("Data", "Spatial", "Downscaled"), pattern="Normal", full.names=T))
  names(climate) <- sapply(sapply(sapply(sapply(list.files(here("Data", "Spatial", "Downscaled"), pattern="Normal", full.names=T), strsplit, split="2010_"), "[", 2), strsplit, split="-downscaled.tif"), "[", 1)
  climate.re <- resample(climate, aspen90, method="near", threads=T, filename=here("Data", "Spatial", "Downscaled", "Normals90.tif"),overwrite=TRUE)
}

# future climate data
select.scenarios<- c("ssp245", "ssp585")
select.years.all <- c("_2011_2040_", "_2041_2070_", "_2071_2100_")
for(select.scenario in select.scenarios){
    for(select.years in select.years.all){
      if(!file.exists(paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, select.years,  "90.tif"))){
          aspen90 <- rast(here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic-90.tif"))
        climate <- list.files(here("Data", "Spatial", "Downscaled"), pattern=paste0("ensemble_8GCMs_", select.scenario, select.years), full.names=T)
        climate <- rast(climate) %>% terra::project(crs(aspen90))
        names(climate) <- sapply(sapply(sapply(sapply(list.files(here("Data", "Spatial", "Downscaled"), pattern=paste0("ensemble_8GCMs_", select.scenario, select.years), full.names=F), strsplit, split=paste0("ensemble_8GCMs_", select.scenario, select.years)), "[", 2), strsplit, split="-downscaled.tif"), "[", 1)
        climate.re <- resample(climate, aspen90, method="near", threads=T, filename=paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, select.years,  "90.tif"),overwrite=TRUE)
      }
    }
}

```

## Modeling Approach

### Overview

To characterize suitable habitat for aspen, we used four different modeling approaches commonly applied in species distribution modeling, generalized linear models (GLMs), generalized additive models (GAMs), and random forests (RFs), and regularized gradient boosted tree (RGBTs). Here, we first overview our modeling approach before describing specifics for individual modeling techniques. All models were fit in *R* [@rcoreteam2022LanguageEnvironmentStatistical] using a *tidymodels* framework [@tidymodels].

To build GLM, GAM, RF, and GBT models, we first constructed a balanced data consisting of 10,000 pixels with aspen present and 10,000 pixels without aspen. To minimize the potential effects of spatial autocorrelation, pixels were selected so that they were separated by at least 1 km. To improve model fit and interpretability, all predictor variables were standardized by calculating standard scores. Using this dataset, we reduced our set of environmental predictors to minimize the potential effects of collinearity on model inference and projection. Specifically, we used the *spatialRF* [@spatialRF] to calculate variable inflation factors (VIF), which indicate when a predictor variable is a linear combinations of other predictor variables. We then iteratively removed variables until VIF\<5 for all variables.

To build and evaluate models, we then split our dataset into equally-sized testing and training datasets. The testing dataset was further split to create five spatial cross-validation folds using the *spatialsample* package [@spatialsample]. We then tuned model hyperparameters using spatial cross-validation and identified the best hyperparameters based on the area under the receiver operator curve (AUC). To evaluate the capacity of our model to predict to new areas, we then fit the model using the best hyperparameters to each spatial cross-validation fold and assessed the variation in the AUC statistic. Given the model's ability to predict aspen habitat in new areas, we then fit a final model to the training dataset and predicted the probability of aspen presence for the testing dataset. Using the *probably* package [@probably], we determined the probability threshold that maximized the Youden's J statistic [@youden1950IndexRatingDiagnostic] and then calculated class-based accuracy statistics based on this threshold.

To better understand the environmental drivers of aspen's distribution and assess model realism, we calculated variable importance scores for each model using a model-agnostic permutation-based approach. In this approach each variable is randomized and then the AUC statistic is compared with AUC for the full model (where data has not been randomized). We also evaluated the relationship between aspen presence and each predictor variable using accumulated local effects (ALE) profiles [@apley2020VisualizingEffectsPredictor]. Variable importance and ALE were calculated in R using the *DALEX* [@DALEX] and *ALEPlot* [@ALEPlot] packages.

```{r DataPrep, eval=F}
select.variables <- c("ADI",   "PRATIO", "GSPDD5",  "GSP","TD","DD_0", "RH")
# Import response variable
aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
names(aspen90.prob) <- "aspen.prob"
aspen90.prob01 <- aspen90.prob
aspen90.prob01[aspen90.prob01>0]<-1
names(aspen90.prob01) <- "aspen.presence"

SRM <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp")) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs(aspen90.prob))
aspen90.prob <- terra::mask(aspen90.prob, SRM)
aspen90.prob01 <-terra::mask(aspen90.prob01, SRM)

# Import predictor variables
topo90 <- rast(here("Data", "Spatial", "DEM", "Topo90.tif"))
elev <- rast(here("Data", "Spatial", "DEM", "DEM250.tif"))
soil90 <- rast(here("Data", "Spatial", "Soils", "Soils90.tif"))
normals90 <- rast(here("Data", "Spatial", "Downscaled", "Normals90.tif"))
normals90 <- normals90[[select.variables]]

# Compile data
aspen.pts <- aspen90.prob01 %>% as.points(na.rm=T)
aspen.pts <- terra::extract(aspen90.prob,aspen.pts, bind=T, xy=T, cells=T) 
aspen.pts <- extract(topo90, aspen.pts, bind=T)
aspen.pts <- extract(soil90, aspen.pts, bind=T)
aspen.pts <-  extract(normals90, aspen.pts, bind=T)

# Spatially thin data
template <- rast(here("Data", "Spatial", "Climate", "ClimateNA", "Derived", "Normal_1981_2010_GSPDD5.tif")) %>% as.points(na.rm=T) %>% terra::project(crs(aspen90.prob))
aspen90.1km <- extract(aspen90.prob,template,cells=T) 
aspen.sample.pts <- aspen.pts %>% as.data.frame() %>% filter(cell %in% aspen90.1km$cell) 

# Remove collinear variables
dat <- aspen.sample.pts %>% na.omit()
dat$aspen.presence <- dat$aspen.presence %>% as.factor()
pred.vars <- dat[, c(select.variables, "om", "tpi3", "pH", "thetas", "clay", "hli")] %>% spatialRF::auto_vif(vif.threshold = 5, preference.order = select.variables)

pred.vars <- pred.vars$selected.variables
remove.vars <- c(select.variables, "om", "tpi3", "pH", "thetas", "tpi15", "clay", "hli")[!c(select.variables, "om", "tpi3", "pH", "thetas", "tpi15", "clay", "hli") %in% pred.vars]
varz <- data.frame(variable=c(pred.vars, remove.vars), include=c(rep("include", length(pred.vars)), rep("remove", length(remove.vars))))

write.csv(varz, here("Results", "Final-variables.csv"), row.names=F)

dat_split <- initial_split(
  dat <- dat %>% group_by(aspen.presence) %>% sample_n(size=10000),
  prop = 0.5, 
  strata = aspen.presence
)

dat.training <-  training(dat_split)
dat.testing <- testing(dat_split)

dat.training %>% write.csv(here("Data", "dat_training.csv"))
dat.testing %>% write.csv(here("Data", "dat_testing.csv"))
# preprocessing "recipe"
presence.recipe<- 
  recipe(aspen.presence ~ ., data = dat.training)  %>%
  # remove collinear variables
  step_rm(!!!syms(remove.vars)) %>% 
  # normalize all numeric variables except the outcome and ID variables
  step_normalize(all_numeric(), -all_outcomes(), -aspen.prob,-cell) %>%
  update_role(aspen.prob,cell, new_role="ID")

# split training dataset to tune hyperparameters
cv_folds <- dat.training %>% st_as_sf(coords=c("x", "y"), remove=F) %>%  st_set_crs(crs(aspen90.prob)) %>%  spatial_clustering_cv(v=5) 

```

### Generalized linear models

GLMs are extensions of parametric linear regression adapted to distributions other than the normal distribution [@zuur2007AnalysingEcologicalData]. Here we constructed GLMs with a logit link function and a binomial error distribution to account for the structure of presence-absence data. We included both linear and quadratic effects for all variables, but did not explore any interaction terms. We fit GLMs using a Lasso regularization approach, which allows for model coefficients to be reduced to zero, thereby limiting model complexity and improving bias-variance tradeoffs [@hastie2009ElementsStatisticalLearning]. Prior to fitting the model to the full training dataset, we tuned the lasso penalty term. GLMs were fit using the *glmnet* package [@glmnet].

```{r GLM, eval=F}
# Specify model
glm_spec <- 
  logistic_reg(penalty = tune(),mixture = 1) %>%
  set_engine("glmnet") %>% 
  set_mode("classification")

# Create workflow
glm_wflow <- 
  workflow() %>% 
  add_recipe(presence.recipe) %>% 
  add_model(glm_spec, formula=aspen.presence~ poly(ADI, 2, raw = TRUE) + poly(PRATIO,2, raw = TRUE) + poly(TD, 2, raw = TRUE) + poly(tpi3, 2, raw = TRUE)  + poly(clay, 2, raw = TRUE))

# Tune model
### Set parameters to be tuned
glm_params <- 
  dials::parameters(
    penalty()
)

## Create grid of search values
glm_grid <- 
  dials::grid_latin_hypercube(
    glm_params, 
    size = 50
)

### Perform tuning
glm_tuned <- tune::tune_grid(
  object = glm_wflow,
  resamples = cv_folds,
  grid = glm_grid,
  metrics = metric_set(recall, precision, f_meas, accuracy, kap, roc_auc, sens, spec),
  control = tune::control_grid(verbose = TRUE)
)

# Finalize workflow
glm_best_params <- glm_tuned  %>% tune::select_best("roc_auc") 
glm_fwflow <- glm_wflow %>% finalize_workflow(glm_best_params)
write.csv(glm_best_params, here("Results", "glm-bestparams.csv"))

# Evaluate model on training dataset
glm_res <- 
  glm_fwflow %>% 
  fit_resamples(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, f_meas, accuracy, kap, roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)
    ) 

glm_res %>%  collect_metrics(summarize = TRUE) %>% mutate(Dataset="training") %>% mutate(Model="GLM") %>% write.csv(here("Results", "GLM-training-stats.csv"))

# Evaluate model on testing dataset
glm_last_fit <- last_fit(glm_fwflow,
                         split=dat_split,
                         metrics = metric_set(recall, precision, f_meas, accuracy, kap,roc_auc, sens, spec))

glm_last_fit %>% collect_metrics() %>% mutate(Dataset="testing", Model="GLM") %>% write.csv(here("Results", "GLM-testing-stats.csv"))

# Save model coefficients
coef_glm <- pluck(glm_last_fit$.workflow, 1) %>% extract_fit_parsnip() %>%  tidy() %>% write.csv(here("Results", "GLM-coef.csv"))


# Best threshold
pluck(glm_last_fit$.workflow, 1) %>% 
  predict(new_data=dat.testing, type="prob") %>%
  bind_cols(dat.testing) %>%
  threshold_perf(truth=aspen.presence, estimate=`.pred_1`, threshold=seq(0,1, by=0.0025), event_level="second") %>%
  write.csv(here("Results", "GLM-prediction-threshold.csv"))

read.csv(here("Results", "GLM-prediction-threshold.csv")) %>%
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold) -> threshold.glm

# Variable importance
explainer_glm <- explain_tidymodels(pluck(glm_last_fit$.workflow, 1),
                                    data=dat.testing%>% as.data.frame() %>% select(-aspen.presence), 
                                    y=dat.testing %>% pull(aspen.presence) %>% as.numeric() - 1,
                                    type="classification", verbose=F
)
explainer_glm %>% feature_importance(type='ratio') %>% as.data.frame() %>% mutate(Model="GLM") %>% write.csv( here("Results", "vip-glm.csv"))

# Partial dependence and accumulated local effects
pdp <- model_profile(explainer_glm , N = 500, variables = pred.vars, type="partial")
pdp$agr_profiles %>% mutate(method="PDP", Model="GLM") %>% write.csv(here("Results", "pdp-GLM.csv"))
ale <- model_profile(explainer_glm , N = 500, variables = pred.vars, type="accumulated")
ale$agr_profiles %>% mutate(method="ALE", Model="GLM")  %>% write.csv(here("Results", "ale-GLM.csv"))

# predict on entire dataset in five separate chunks
aspen.pts.df <- aspen.pts %>% as.data.frame() %>% na.omit()
aspen.pts.df$cut <- cut(1:nrow(aspen.pts.df), breaks=5)
aspen.pts.df$predicted <- NA
for(j in unique(aspen.pts.df$cut)){
   all_prediction <- pluck(glm_last_fit$.workflow,1) %>% 
     predict(new_data = aspen.pts.df[aspen.pts.df$cut==j, ], type="prob")
  aspen.pts.df[aspen.pts.df$cut==j, ]$predicted <- all_prediction$`.pred_1`
  #print(j)
}

aspen90.pred <- aspen90.prob01
aspen90.pred.cells <- cells(aspen90.pred)
aspen90.pred[!aspen90.pred.cells] <-  -9999
aspen90.pred.bak <- aspen90.pred

aspen90.pred <- aspen90.prob01
aspen90.pred[aspen.pts.df$cell] <-  aspen.pts.df$predicted
writeRaster(aspen90.pred, here("Data", "Spatial", "Predictions","predicted_1981-2010-glm.tif"), overwrite=T)

# Predict
select.scenarios<- c( "ssp245", "ssp585")
select.years.all <- c("_2011_2040", "_2041_2070", "_2071_2100")
for(select.scenario in select.scenarios){
  for(years in select.years.all){
      climate90 <- rast(paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, years, "_90.tif"))[[c("ADI",   "PRATIO", "GSPDD5", "TD", "DD_0", "RH")]]
    # Compile data
    aspen.pts <- aspen90.prob01 %>% as.points(na.rm=T)
    aspen.pts <- terra::extract(aspen90.prob,aspen.pts, bind=T, xy=T, cells=T) 
    aspen.pts <- extract(climate90, aspen.pts, bind=T)
    aspen.pts$GSP <- -9999
    aspen.pts <- extract(topo90, aspen.pts, bind=T)
    aspen.pts <- extract(soil90, aspen.pts, bind=T)
    
    # predict on entire dataset in five separate chunks
    aspen.pts.df <- aspen.pts %>% as.data.frame() %>% na.omit()
    aspen.pts.df <- aspen.pts.df[,colnames(dat.training)]
    aspen.pts.df$predicted <- NA
    aspen.pts.df$cut <- cut(1:nrow(aspen.pts.df), breaks=5)
    for(j in unique(aspen.pts.df$cut)){
      all_prediction <- pluck(glm_last_fit$.workflow,1) %>% 
        predict(new_data = aspen.pts.df[aspen.pts.df$cut==j, ], type="prob")
      aspen.pts.df[aspen.pts.df$cut==j, ]$predicted <- all_prediction$`.pred_1`
    }
  
    aspen90.pred <- aspen90.prob01
    aspen90.pred[aspen.pts.df$cell] <-  aspen.pts.df$predicted
    
    writeRaster(aspen90.pred, paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-glm.tif"),overwrite=T)
  }
}

```

### Generalized additive models

GAMs are a non-parametric extension of GLMs that are particularly useful when there is no *a priori* reason for fitting a particular relationship (e.g., linear, quadratic). Here, we construct binomial GAMs with a logit link function using the *mgcv* package [@mgcv]. In our model, we represented the relationships between the response and each predictor variable using thin plate regression splines, where the penalty term was adjusted to allow the term to be shrunk to zero. For all smooths, we set the k parameter, which sets the number of basis functions, to the default value of 10, after using built in diagnostic function from the *mgcv* package to confirm an adequate degree of complexity. To limit overfitting, we tuned the penalty term prior to fitting the model to the full training dataset. GAMs were fit using restricted maximum likelihood (REML), following recommenddations from Pedersen et al. [-@pedersen2018HierarchicalGeneralizedAdditive].

```{r GAM, eval=F}
# Specify model
gam_spec <- 
  gen_additive_mod(select_features =  T, adjust_deg_free = tune()) %>%
  set_engine("mgcv", family = binomial(link = "logit"), method = "REML") %>% 
  set_mode("classification")

# Create workflow
gam_wflow <- 
  workflow() %>% 
  add_recipe(presence.recipe) %>% 
  add_model(gam_spec, formula=aspen.presence~s(ADI, bs="ts")+s(PRATIO,bs="ts")+s(GSPDD5,bs="ts")+s(TD,bs="ts")+s(tpi3,bs="ts")+s(clay,bs="ts")+s(clay,bs="ts")+s(hli,bs="ts")) 

# Tune model
### Set parameters to be tuned
gam_params <- 
  dials::parameters(
    adjust_deg_free()
)

## Create grid of search values
gam_grid <- 
  dials::grid_latin_hypercube(
    gam_params, 
    size = 50
)


### Perform tuning
gam_tuned <- tune::tune_grid(
  object = gam_wflow,
  resamples = cv_folds,
  grid = gam_grid,
  metrics = metric_set(recall, precision, f_meas, accuracy, kap, roc_auc, sens, spec),
  control = tune::control_grid(verbose = TRUE)
)

# Finalize workflow
gam_best_params <- gam_tuned  %>% tune::select_best("roc_auc") 
gam_fwflow <- gam_wflow %>% finalize_workflow(gam_best_params)
write.csv(gam_best_params, here("Results", "gam-bestparams.csv"))

# Evaluate model on training dataset
gam_res <- 
  gam_fwflow %>% 
  fit_resamples(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, f_meas, accuracy, kap, roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)
    ) 

gam_res %>% collect_metrics(summarize = TRUE) %>% mutate(Dataset="training") %>% mutate(Model="GAM") %>% write.csv(here("Results", "GAM-training-stats.csv"))

# Evaluate model on testing dataset
gam_last_fit <- last_fit(gam_fwflow,
                         split=dat_split,
                         metrics = metric_set(recall, precision, f_meas, accuracy, kap,roc_auc, sens, spec))

gam_last_fit %>% collect_metrics() %>% mutate(Dataset="testing", Model="GAM") %>% write.csv(here("Results", "GAM-testing-stats.csv"))


# Best threshold
pluck(gam_last_fit$.workflow, 1) %>% 
  predict(new_data=dat.testing, type="prob") %>%
  bind_cols(dat.testing) %>%
  threshold_perf(truth=aspen.presence, estimate=`.pred_1`, threshold=seq(0,1, by=0.0025), event_level="second") %>%
  write.csv(here("Results", "GAM-prediction-threshold.csv"))

read.csv(here("Results", "GAM-prediction-threshold.csv")) %>%
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold) -> threshold.gam


# Variable importance
explainer_gam <- explain_tidymodels(pluck(gam_last_fit$.workflow, 1), 
                                    data=dat.testing%>% as.data.frame() %>% select(-aspen.presence), 
                                    y=dat.testing %>% pull(aspen.presence) %>% as.numeric()-1,
                                    type="classification", verbose=F
)

explainer_gam %>% feature_importance(type="ratio")  %>% as.data.frame() %>% mutate(Model="GAM") %>% write.csv( here("Results", "vip-gam.csv"))

# Partial dependence and accumulated local effects
pdp <- model_profile(explainer_gam , N = 500, variables = pred.vars, type="partial")
pdp$agr_profiles %>% mutate(method="PDP", Model="GAM") %>% write.csv(here("Results", "pdp-GAM.csv"))
ale <- model_profile(explainer_gam , N = 500, variables = pred.vars, type="accumulated")
ale$agr_profiles %>% mutate(method="ALE", Model="GAM")  %>% write.csv(here("Results", "ale-GAM.csv"))

# predict on entire dataset in five separate chunks
aspen.pts.df <- aspen.pts %>% as.data.frame() %>% na.omit()
aspen.pts.df$cut <- cut(1:nrow(aspen.pts.df), breaks=5)
aspen.pts.df$predicted <- NA
for(j in unique(aspen.pts.df$cut)){
  all_prediction <-pluck(gam_last_fit$.workflow, 1) %>% 
        predict(new_data = aspen.pts.df[aspen.pts.df$cut==j, ], type="prob")
  aspen.pts.df[aspen.pts.df$cut==j, ]$predicted <- all_prediction$`.pred_1`
  #print(j)
}

aspen90.pred <- aspen90.prob01
aspen90.pred.cells <- cells(aspen90.pred)
aspen90.pred[!aspen90.pred.cells] <-  -9999
aspen90.pred[aspen.pts.df$cell] <-  aspen.pts.df$predicted
writeRaster(aspen90.pred, here("Data", "Spatial", "Predictions", "predicted_1981-2010-gam.tif"), overwrite=T)



# Predict
select.scenarios<- c( "ssp245", "ssp585")
select.years.all <- c("_2011_2040", "_2041_2070", "_2071_2100")
for(select.scenario in select.scenarios){
  for(years in select.years.all){
    if(!file.exists( paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-gam.tif"))){
          climate90 <- rast(paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, years, "_90.tif"))[[c("ADI",   "PRATIO", "GSPDD5", "TD", "DD_0", "RH")]]
    # Compile data
    aspen.pts <- aspen90.prob01 %>% as.points(na.rm=T)
    aspen.pts <- terra::extract(aspen90.prob,aspen.pts, bind=T, xy=T, cells=T) 
    aspen.pts <- extract(climate90, aspen.pts, bind=T)
    aspen.pts$GSP <- -9999
    aspen.pts <- extract(topo90, aspen.pts, bind=T)
    aspen.pts <- extract(soil90, aspen.pts, bind=T)
    
    # predict on entire dataset in five separate chunks
    aspen.pts.df <- aspen.pts %>% as.data.frame() %>% na.omit()
    aspen.pts.df <- aspen.pts.df[,colnames(testing(dat_split))]
    aspen.pts.df$predicted <- NA
    aspen.pts.df$cut <- cut(1:nrow(aspen.pts.df), breaks=5)
    for(j in unique(aspen.pts.df$cut)){
      all_prediction <- pluck(gam_last_fit$.workflow, 1) %>% 
        predict(new_data = aspen.pts.df[aspen.pts.df$cut==j, ], type="prob")
      aspen.pts.df[aspen.pts.df$cut==j, ]$predicted <- all_prediction$`.pred_1`
    }
    
    aspen90.pred <- aspen90.prob01
    aspen90.pred.cells <- cells(aspen90.pred)
    aspen90.pred[!aspen90.pred.cells] <-  -9999
    aspen90.pred.bak <- aspen90.pred
    
    aspen90.pred <- aspen90.prob01
    aspen90.pred[aspen.pts.df$cell] <-  aspen.pts.df$predicted
    writeRaster(aspen90.pred, paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-gam.tif"),overwrite=T)
    }

  }
}
```

### Random Forests

RF models are an extension of classification and regression tree analysis (CART; @breiman1984ClassificationRegressionTrees), a nonparametric approach where decision trees are used to explain the variation in the response variable by repeatedly splitting the data into more similar groups [@death2000]. Tree-based approaches are useful for modeling nonlinear relationships and complex interactions among variables, which often characterize ecological data [@death2000; @cutler2007RandomForestsClassification]. RF builds upon bagging methods, where many trees are built using random samples (with replacement) of the training data and predictions are generated from the ensemble set of trees. While bagging reduces some of the overfitting issues associated with CART, RF methods also limit the number of variables to consider at any given split to a random subset and the complexity of each tree by limiting splits to only nodes with a minimum number of data points. The inclusion of these hyperparameters results in less correlation among trees and thus better bias-variance tradeoffs [@cutler2007RandomForestsClassification]. Prior to fitting the model to the full training dataset, we tuned these hyperparameters, while holding the number of trees constant at 1000. RF models were fit using the tidymodels implementation of the *ranger* package [@ranger].

```{r RF, eval=F}
# Specify model
rf_spec <- 
  rand_forest(
    trees=1000,
    min_n=tune(),
    mtry=tune()
  ) %>%
  set_engine("ranger", importance = "permutation", seed = 123) %>% 
  set_mode("classification")

# Create workflow
rf_wflow <- 
  workflow() %>% 
  add_recipe(presence.recipe) %>% 
  add_model(rf_spec)

# Tune model
### Set parameters to be tuned
rf_params <- 
  dials::parameters(
    finalize(mtry(),select(aspen.sample.pts,all_of(pred.vars))),
    min_n()
)

## Create grid of search values
rf_grid <- 
  dials::grid_latin_hypercube(
    rf_params, 
    size = 50
)

### Perform tuning
rf_tuned <- tune::tune_grid(
  object = rf_wflow,
  resamples = cv_folds,
  grid = rf_grid,
  metrics = metric_set(recall, precision, f_meas, accuracy, kap, roc_auc, sens, spec),
  control = tune::control_grid(verbose = TRUE)
)

# Finalize workflow
rf_best_params <- rf_tuned %>% tune::select_best("roc_auc")
rf_fwflow <- rf_wflow %>% finalize_workflow(rf_best_params)
write.csv(rf_best_params, here("Results", "rf-bestparams.csv"))

# Evaluate model on training dataset
rf_res <- 
  rf_fwflow %>% 
  fit_resamples(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, f_meas, accuracy, kap, roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)
    ) 

rf_res %>%  collect_metrics(summarize = TRUE) %>% mutate(Dataset="training") %>% mutate(Model="RF") %>% write.csv(here("Results", "RF-training-stats.csv"))

# Evaluate model on testing dataset
rf_last_fit <- last_fit(rf_fwflow,
                         split=dat_split,
                         metrics = metric_set(recall, precision, f_meas, accuracy, kap,roc_auc, sens, spec))

rf_last_fit %>% collect_metrics() %>% mutate(Dataset="testing", Model="RF") %>% write.csv(here("Results", "RF-testing-stats.csv"))


# Best threshold
pluck(rf_last_fit$.workflow, 1) %>% 
  predict(new_data=dat.testing, type="prob") %>%
  bind_cols(dat.testing) %>%
  threshold_perf(truth=aspen.presence, estimate=`.pred_1`, threshold=seq(0,1, by=0.0025), event_level="second") %>%
  write.csv(here("Results", "RF-prediction-threshold.csv"))

read.csv(here("Results", "RF-prediction-threshold.csv")) %>%
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold) -> threshold.rf



# Variable importance

explainer_rf<- explain_tidymodels(pluck(rf_last_fit$.workflow, 1), 
                                    data=dat.testing %>% as.data.frame() %>% select(-aspen.presence), 
                                    y=dat.testing%>% pull(aspen.presence) %>% as.numeric()-1,
                                    type="classification", verbose=F
)

explainer_rf %>% feature_importance(type="ratio") %>% as.data.frame() %>% mutate(Model="RF") %>% write.csv( here("Results", "vip-rf.csv"))

# Partial dependence and accumualted local effects
pdp <- model_profile(explainer_rf , N = 500, variables = pred.vars, type="partial")
pdp$agr_profiles %>% mutate(method="PDP", Model="RF") %>% write.csv(here("Results", "pdp-rf.csv"))
ale <- model_profile(explainer_rf , N = 500, variables = pred.vars, type="accumulated")
ale$agr_profiles %>% mutate(method="ALE", Model="RF")  %>% write.csv(here("Results", "ale-rf.csv"))

# predict on entire dataset in five separate chunks
aspen.pts.df <- aspen.pts %>% as.data.frame() %>% na.omit()
aspen.pts.df$cut <- cut(1:nrow(aspen.pts.df), breaks=5)
aspen.pts.df$predicted <- NA
for(j in unique(aspen.pts.df$cut)){
  all_prediction <-pluck(rf_last_fit$.workflow, 1) %>% 
        predict(new_data = aspen.pts.df[aspen.pts.df$cut==j, ], type="prob")
  aspen.pts.df[aspen.pts.df$cut==j, ]$predicted <- all_prediction$`.pred_1`
}

aspen90.pred <- aspen90.prob01
aspen90.pred.cells <- cells(aspen90.pred)
aspen90.pred[!aspen90.pred.cells] <-  -9999
aspen90.pred.bak <- aspen90.pred

aspen90.pred <- aspen90.prob01
aspen90.pred[aspen.pts.df$cell] <-  aspen.pts.df$predicted
writeRaster(aspen90.pred, here("Data", "Spatial", "Predictions", "predicted_1981-2010-rf.tif"),overwrite=T)

# Predict
select.scenarios<- c("ssp245", "ssp585")
select.years.all <- c("_2011_2040", "_2041_2070", "_2071_2100")
for(select.scenario in select.scenarios){
  for(years in select.years.all){
    if(!file.exists(paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-rf.tif"))){
      climate90 <- rast(paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, years, "_90.tif"))[[c("ADI",   "PRATIO", "GSPDD5", "TD", "DD_0", "RH")]]
    # Compile data
    aspen.pts <- aspen90.prob01 %>% as.points(na.rm=T)
    aspen.pts <- terra::extract(aspen90.prob,aspen.pts, bind=T, xy=T, cells=T) 
    aspen.pts <- extract(climate90, aspen.pts, bind=T)
    aspen.pts$GSP <- -9999
    aspen.pts <- extract(topo90, aspen.pts, bind=T)
    aspen.pts <- extract(soil90, aspen.pts, bind=T)
    
    # predict on entire dataset in five separate chunks
    aspen.pts.df <- aspen.pts %>% as.data.frame() %>% na.omit()
    aspen.pts.df <- aspen.pts.df[,colnames(testing(dat_split))]
    aspen.pts.df$predicted <- NA
    aspen.pts.df$cut <- cut(1:nrow(aspen.pts.df), breaks=5)
    for(j in unique(aspen.pts.df$cut)){
      all_prediction <-pluck(rf_last_fit$.workflow, 1) %>% 
        predict(new_data = aspen.pts.df[aspen.pts.df$cut==j, ], type="prob")
      aspen.pts.df[aspen.pts.df$cut==j, ]$predicted <- all_prediction$`.pred_1`
    }
    
    aspen90.pred <- aspen90.prob01
    aspen90.pred.cells <- cells(aspen90.pred)
    aspen90.pred[!aspen90.pred.cells] <-  -9999
    aspen90.pred.bak <- aspen90.pred
    
    aspen90.pred <- aspen90.prob01
    aspen90.pred[aspen.pts.df$cell] <-  aspen.pts.df$predicted
    writeRaster(aspen90.pred, paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-rf.tif"),overwrite=T)
    }
  }
}
```

### Regularized gradient boosting trees

Gradient boosted trees (GBTs) are also an ensemble-based extension of CART [@death2007BoostedTreesEcological]. In contrast to RF where trees are built in parallel, individual trees in a GBT ensemble are constructed iteratively so that each successive tree attempts to improve upon predictions made by the previous tree [@friedman2001GreedyFunctionApproximation]. To improve bias-variance tradeoffs, GBTs incorporate hyperparameters that control the rate at which the boosting algorithm adapt, and introduce randomness into the tree construction by sampling both variables (i.e., columns) and cases (i.e., rows) used to fit the model. RGBTs expand upon these approaches by incorporating regularization terms that constrain the depth of the tree and setting limits on the amount of gain in model fit required to further partition a node of the tree. We tune these hyperparameters prior to fitting the model to the full training dataset. RGBTs were fit using the R package *xgboost* [@xgboost].

```{r XGB, eval=F}
# Specify model
xgb_spec <- 
  boost_tree(
    trees=1000,
    tree_depth=tune(), #the maximum depth of the tree (i.e. number of splits).
    min_n=tune(), #the minimum number of data points in a node that are required for the node to be split further
    loss_reduction=tune(), # The reduction in the loss function required to split further
    sample_size=tune(), # The amount of data exposed to the fitting routine
    mtry=tune(), #The number of predictors that will be randomly sampled at each split when creating the tree models
    learn_rate=tune(), # The rate at which the boosting algorithm adapts from iteration-to-iteration.
    stop_iter = tune() # The number of iterations without an improvement in the objective function occur before training should be halted
  ) %>%
  set_engine("xgboost", objective = "binary:logistic", validation = 0.2) %>% 
  set_mode("classification")

# Create workflow
xgb_wflow <- 
  workflow() %>% 
  add_recipe(presence.recipe) %>% 
  add_model(xgb_spec)

# Tune model
## Create grid of search values
xgboost_grid <- 
  dials::grid_latin_hypercube(
      tree_depth(),
      min_n(),
      loss_reduction(),
      sample_size = sample_prop(), # needs to be a proportion
      finalize(mtry(), training_data), 
      learn_rate(),
      stop_iter(),
      size = 50
)

### Perform tuning
xgb_tuned <- tune::tune_grid(
  object = xgb_wflow,
  resamples = cv_folds,
  grid = xgboost_grid,
  metrics = metric_set(recall, precision, f_meas, accuracy, kap, roc_auc, sens, spec),
  control = tune::control_grid(verbose = TRUE)
)

# Finalize workflow
xgb_best_params <- xgb_tuned  %>% tune::select_best("roc_auc") 
xgb_fwflow <- xgb_wflow %>% finalize_workflow(xgb_best_params)
write.csv(xgb_best_params, here("Results", "xgb-bestparams.csv"))

# Evaluate model on training dataset
xgb_res <- 
  xgb_fwflow %>% 
  fit_resamples(
    resamples = cv_folds, 
    metrics = metric_set(recall, precision, f_meas, accuracy, kap, roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)
    ) 

xgb_res %>% collect_metrics(summarize = TRUE) %>% mutate(Dataset="training") %>% mutate(Model="XGB") %>% write.csv(here("Results", "XGB-training-stats.csv"))


# Evaluate model on testing dataset
xgb_last_fit <- last_fit(xgb_fwflow,
                         split=dat_split,
                         metrics = metric_set(recall, precision, f_meas, accuracy, kap,roc_auc, sens, spec))

xgb_last_fit %>% collect_metrics() %>% mutate(Dataset="testing", Model="XGB") %>% write.csv(here("Results", "XGB-testing-stats.csv"))


# Best threshold
pluck(xgb_last_fit$.workflow, 1) %>% 
  predict(new_data=dat.testing, type="prob") %>%
  bind_cols(dat.testing) %>%
  threshold_perf(truth=aspen.presence, estimate=`.pred_1`, threshold=seq(0,1, by=0.0025), event_level="second") %>%
  write.csv(here("Results", "XGB-prediction-threshold.csv"))

read.csv(here("Results", "XGB-prediction-threshold.csv")) %>%
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold) -> threshold.xgb


# Variable importance
explainer_xgb <- explain_tidymodels(pluck(xgb_last_fit$.workflow, 1), 
                                    data=dat.testing%>% as.data.frame() %>% select(-aspen.presence), 
                                    y=dat.testing %>% pull(aspen.presence) %>% as.numeric()-1,
                                    type="classification", verbose=F
)

explainer_xgb %>% feature_importance(type="ratio")  %>% as.data.frame() %>% mutate(Model="XGB") %>% write.csv( here("Results", "vip-xgb.csv"))

# Partial dependence and accumulated local effects
pdp <- model_profile(explainer_xgb , N = 500, variables = pred.vars, type="partial")
pdp$agr_profiles %>% mutate(method="PDP", Model="XGB") %>% write.csv(here("Results", "pdp-XGB.csv"))
ale <- model_profile(explainer_xgb , N = 500, variables = pred.vars, type="accumulated")
ale$agr_profiles %>% mutate(method="ALE", Model="XGB")  %>% write.csv(here("Results", "ale-XGB.csv"))


# predict on entire dataset in five separate chunks
aspen.pts.df <- aspen.pts %>% as.data.frame() %>% na.omit()
aspen.pts.df$cut <- cut(1:nrow(aspen.pts.df), breaks=5)
aspen.pts.df$predicted <- NA
for(j in unique(aspen.pts.df$cut)){
  all_prediction <-pluck(xgb_last_fit$.workflow, 1) %>% 
        predict(new_data = aspen.pts.df[aspen.pts.df$cut==j, ], type="prob")
  aspen.pts.df[aspen.pts.df$cut==j, ]$predicted <- all_prediction$`.pred_1`
  #print(j)
}

aspen90.pred <- aspen90.prob01
aspen90.pred.cells <- cells(aspen90.pred)
aspen90.pred[!aspen90.pred.cells] <-  -9999
aspen90.pred[aspen.pts.df$cell] <-  aspen.pts.df$predicted
writeRaster(aspen90.pred, here("Data", "Spatial", "Predictions", "predicted_1981-2010-xgb.tif"), overwrite=T)


# Predict
select.scenarios<- c( "ssp245", "ssp585")
select.years.all <- c("_2011_2040", "_2041_2070", "_2071_2100")
for(select.scenario in select.scenarios){
  for(years in select.years.all){
    if(!file.exists( paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-xgb.tif"))){
          climate90 <- rast(paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, years, "_90.tif"))[[c("ADI",   "PRATIO", "GSPDD5", "TD", "DD_0", "RH")]]
    # Compile data
    aspen.pts <- aspen90.prob01 %>% as.points(na.rm=T)
    aspen.pts <- terra::extract(aspen90.prob,aspen.pts, bind=T, xy=T, cells=T) 
    aspen.pts <- extract(climate90, aspen.pts, bind=T)
    aspen.pts$GSP <- -9999
    aspen.pts <- extract(topo90, aspen.pts, bind=T)
    aspen.pts <- extract(soil90, aspen.pts, bind=T)
    
    # predict on entire dataset in five separate chunks
    aspen.pts.df <- aspen.pts %>% as.data.frame() %>% na.omit()
    aspen.pts.df <- aspen.pts.df[,colnames(testing(dat_split))]
    aspen.pts.df$predicted <- NA
    aspen.pts.df$cut <- cut(1:nrow(aspen.pts.df), breaks=5)
    for(j in unique(aspen.pts.df$cut)){
      all_prediction <- pluck(xgb_last_fit$.workflow, 1) %>% 
        predict(new_data = aspen.pts.df[aspen.pts.df$cut==j, ], type="prob")
      aspen.pts.df[aspen.pts.df$cut==j, ]$predicted <- all_prediction$`.pred_1`
    }
    
    aspen90.pred <- aspen90.prob01
    aspen90.pred.cells <- cells(aspen90.pred)
    aspen90.pred[!aspen90.pred.cells] <-  -9999
    aspen90.pred.bak <- aspen90.pred
    
    aspen90.pred <- aspen90.prob01
    aspen90.pred[aspen.pts.df$cell] <-  aspen.pts.df$predicted
    writeRaster(aspen90.pred, paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-xgb.tif"),overwrite=T)
    }

  }
}

```

### Model Ensemble

To account for uncertainty due to modelling approach [@araujo2007EnsembleForecastingSpecies], we generated ensemble predictions by combining predictions for each model. Specifically, we calculated a weighted probability of occurrence from all four presence-absence models. We assigned weights based on the AUC statistic. We then comparing the ensemble prediction probability with the testing dataset and determined the probability threshold that maximized the Youden's J statistic [@youden1950IndexRatingDiagnostic]. We used this threshold to calculate class-based accuracy statistics.

```{r WeightedEnsemble}
ensemble.set <- c("GLM", "GAM", "RF", "XGB")
weights <- NULL 
for(j in ensemble.set){
    weights<- c(weights, read.csv(here("Results", paste0(j, "-testing-stats.csv"))) %>% filter(.metric=="roc_auc") %>% select(`.estimate`))
}
names(weights) <- ensemble.set 
weights <- do.call(c, weights)
weights <- weights/sum(weights)

#Normals
stackk<- NULL
if(!file.exists(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"))){
  for(j in ensemble.set){
    stackk <- c(stackk, rast(paste0(here("Data", "Spatial", "Predictions"), "/predicted_1981-2010", "-", j , ".tif"))* weights[j])
  }
  stackj <- sum(do.call(c,stackk))
  writeRaster(stackj, here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"), overwrite=T)
}
  
if(!file.exists(here("Results", "Ensemble-prediction-threshold.csv"))){
  stackj <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"))
  dat.testing <- read.csv(here("Data", "dat_testing.csv"))[,-1]
  x <-  vect(dat.testing, geom=c("x", "y"), crs=crs(stackj))
  x <- extract(stackj, x, bind=T) %>% as.data.frame()
  colnames(x)[1] <- "truth"
  colnames(x)[ncol(x)] <- "estimate"
  x$truth <- factor(x$truth)
    
  # Best threshold
  x %>% threshold_perf(truth="truth", estimate="estimate", threshold=seq(0,1, by=0.0025), event_level="second") %>% write.csv(here("Results", "Ensemble-prediction-threshold.csv"))
}
  
read.csv(here("Results", "Ensemble-prediction-threshold.csv")) %>% 
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold) -> threshold.ensemble
  
# Forecast
select.scenarios<- c("ssp245", "ssp585")
select.years.all <- c("_2011_2040", "_2041_2070", "_2071_2100")
for(select.scenario in select.scenarios){
    for(years in select.years.all){
      if(!file.exists(paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-ensemble.tif"))){
         stackk<- NULL
        for(j in ensemble.set){
        stackk <- c(stackk, (rast(paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-", j , ".tif"))* weights[j]))
        }
       stackj <- stackk[[1]] +stackk[[2]]+stackk[[3]]
       writeRaster(stackj, paste0(here("Data", "Spatial", "Predictions"), "/predicted_ensemble_8GCMs_", select.scenario, years, "-ensemble.tif"), overwrite=T)
       stackj <- NULL
    }
  }
}
```

```{r PerformanceTable}
if(!file.exists(here("results", "photo-accuracy-combined.csv"))){
  # assess accuracy
  predictions.glm <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-glm.tif"))
  predictions.xgb <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-xgb.tif"))
  predictions.rf <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-rf.tif"))
  predictions.gam <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-gam.tif"))
  predictions.ensemble <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"))
  pred <- c(predictions.glm , predictions.xgb,predictions.rf,predictions.gam,predictions.ensemble)
  names(pred) <- c("GLM", "XGB", "RF", "GAM", "Ensemble")
  
  true <-st_read(here("Data", "Spatial", "TrainingPts", "photo_interpretation_points_srme.gpkg"))
  

  
  multi.met <- metric_set(recall, precision, f_meas, accuracy, kap, sens, spec)
  results <- NULL
  for(j in names(pred)){
     read.csv(here("Results", paste0(j,"-prediction-threshold.csv"))) %>%
      filter(.metric == "j_index") %>%
      filter(.estimate == max(.estimate)) %>%
      pull(.threshold) -> threshold
    
      out <-  extract(pred[[j]], true, bind=T) %>% as.data.frame() 
      out$predicted <- ifelse(out[,j] < threshold, 0, 1)
      
      res <- out %>% count(predicted) %>% na.omit() %>% mutate(percent=n/sum(n), model=j) %>% filter(predicted==1)
      results <- rbind(results, res)
  }
  
  write.csv(results, here("results", "photo-accuracy-combined.csv"))
}

if(!file.exists(here("results", "training-accuracy-stats-combined.csv"))){
  # assess accuracy
  predictions.glm <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-glm.tif"))
  predictions.xgb <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-xgb.tif"))
  predictions.rf <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-rf.tif"))
  predictions.gam <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-gam.tif"))
  predictions.ensemble <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"))
  pred <- c(predictions.glm , predictions.xgb,predictions.rf,predictions.gam,predictions.ensemble)
  names(pred) <- c("GLM", "XGB", "RF", "GAM", "Ensemble")
  

  true <- read.csv(here("Data","dat_testing.csv"))
  coordinates(true) <- ~x+y
  crs(true) <- crs(pred)
  true <- true   %>% vect()
  
  multi.met <- metric_set(recall, precision, f_meas, accuracy, kap, sens, spec)
  results <- NULL
  for(j in names(pred)){
     read.csv(here("Results", paste0(j,"-prediction-threshold.csv"))) %>%
      filter(.metric == "j_index") %>%
      filter(.estimate == max(.estimate)) %>%
      pull(.threshold) -> threshold
    
    
    out <-  extract(pred[[j]], true, bind=T) %>% as.data.frame()
    colnames(out) <- c(names(true), "predicted")
    out$aspen.presence <- as.numeric(as.character(out$aspen.presence))
    out <- out %>% mutate(aspen.presence.f= factor(aspen.presence), predicted.f=factor(ifelse(predicted < threshold,0,1)))
    res <- multi.met(data=out, truth=aspen.presence.f, estimate=predicted.f)
    res <- rbind(res, roc_auc(out, aspen.presence.f, predicted, event_level="second")) %>% mutate(model=j)
    results <- rbind(results, res)
  }
  
  write.csv(results, here("results", "training-accuracy-stats-combined.csv"))
}
```

```{r MissClassPatterns}
if(!file.exists(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble-classerror.tif"))){
  # Import response variable
  aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
  names(aspen90.prob) <- "aspen.prob"
  aspen90.prob01 <- aspen90.prob
  aspen90.prob01[aspen90.prob01>0]<-1
  names(aspen90.prob01) <- "aspen.presence"

  SRM <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp")) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs(aspen90.prob))
  aspen90.prob <- terra::mask(aspen90.prob, SRM)
  aspen90.prob01 <-terra::mask(aspen90.prob01, SRM)

  predictions.glm <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-glm.tif"))
  predictions.xgb <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-xgb.tif"))
  predictions.rf <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-rf.tif"))
  predictions.gam <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-gam.tif"))
  predictions.ensemble <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"))

miss.class.fun <- function(predicted= predictions.glm, model="glm", true=aspen90.prob01){
  read.csv(here("Results", paste0(model, "-prediction-threshold.csv"))) %>% 
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>% 
  pull(.threshold) %>% min() -> threshold 
  
  predicted[predicted>=threshold] <- 1
  predicted[predicted<threshold] <- 0
  
  true[true==1] <- 10
  miss <-true - predicted
  miss[miss==-1] <- 2 # false positive
  miss[miss==9] <- 1 # correct
  miss[miss==10] <- -1 # false negative
  
  writeRaster(miss, here("Data", "Spatial", "Predictions", paste0("predicted_1981-2010-", model, "-classerror.tif")),overwrite=T)
}

miss.class.fun(predicted= predictions.glm, model="glm", true=aspen90.prob01)
miss.class.fun(predicted= predictions.gam, model="gam", true=aspen90.prob01)
miss.class.fun(predicted= predictions.rf, model="rf", true=aspen90.prob01)
miss.class.fun(predicted= predictions.xgb, model="xgb", true=aspen90.prob01)
miss.class.fun(predicted= predictions.ensemble, model="ensemble", true=aspen90.prob01)
}
ensemble.error<- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble-classerror.tif"))

  study.area <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp"), quiet=T) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs(ensemble.error)) 
  
  tm.error<-  tm_shape(ensemble.error)+tm_raster(style= "cat", title="", labels=c("false negative","true negative", "true positive", "false positive"), palette=c("#e78ac3", "grey25", "#a6d854", "#377eb8"))+tm_layout(bg.color="white", legend.position = c(0.01,0.85))+tm_shape(study.area) + tm_borders()+ tm_compass( position=c("right", "top"))+ tm_scale_bar(position=c("left", "bottom"))
Fig.file <- here("Results", "Figures", "ensemble-error-map.jpg")
  jpeg(Fig.file, width=3.5, height=5, units="in", res=300)
  tm.error
whatever <- dev.off()


##  Spatial patterns
if(!file.exists(here("Results", "Figures","missclass-geography.jpg"))){
  elev <- rast(here("Data", "Spatial", "DEM", "DEM250.tif"))
  aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
  predictions.ensemble <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble-classerror.tif"))
  
  pts <- predictions.ensemble  %>%  spatSample(size=5000,na.rm=T, method="stratified", as.points=T, exhaustive=F)
  pts <- extract(aspen90.prob, pts, bind=T) %>% terra::project(crs(elev))
  pts <- extract(elev, pts, bind=T, spatial=T)
  pts.coords <- crds(pts %>% terra::project('EPSG:4326') , df=T)
  
  dat <- cbind(as.data.frame(pts), pts.coords)
  colnames(dat) <- c('Class', "Percent aspen", "Elevation (m)", "Longitude (°W)","Latitude (°N)")
  dat$`Percent aspen` <- dat$`Percent aspen`*100
  
  
  dat <- pivot_longer(dat,
      cols = "Percent aspen":"Latitude (°N)", 
      names_to = "variable",
      values_to = "value"
  )
  dat$Class <- factor(dat$Class, levels=c(-1,0,1,2), labels=c("false\nnegative","true\nnegative", "true\npositive", "false\npositive"), ordered=T)
  dat <- dat %>% as.data.frame()
  p1<-ggplot(dat, aes(x=Class, y=value,fill=Class))+geom_boxplot(outlier.size = 0.5)+facet_wrap(~variable, scales="free_y", ncol=1)+theme(legend.position="none", legend.title=element_blank())+ylab("value")+scale_fill_manual(values=c("#e78ac3", "grey25", "#a6d854", "#377eb8"))
  
    ggsave(p1, filename=here("Results", "Figures", "missclass-geography.jpg"), width=3.5, height=4, units="in")
    
    missclass.dat <- dat %>% group_by(Class, variable) %>% summarise(median=median(value)) %>% write.csv(here("Results", "misclass-dat.csv"), row.names=F)
  
}
```

```{r VIP}
pred.vars <- read.csv(here("Results", "Final-variables.csv")) %>% filter(include=="include") %>% pull(variable)
pred.climate.vars <- pred.vars[!pred.vars %in% c("pH", "clay", "thetas", "om", "tpi3", "tpi15", "hli")]

if(!file.exists(here("Results", "Figures", "vip-ale.jpg"))){
  
  normals90 <- rast(here("Data", "Spatial", "Downscaled", "Normals90.tif"))[[pred.climate.vars]]
  
  aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
  names(aspen90.prob) <- "aspen.prob"
  aspen90.prob01 <- aspen90.prob
  aspen90.prob01[aspen90.prob01>0]<-1

  aspen90.prob01.sample <- aspen90.prob01%>% spatSample(size=10000, as.points=T, method="stratified", na.rm=T, exhaustive=T, exp=10) %>% filter(aspen.prob==1)

  normals90.df <- terra::extract(normals90,  aspen90.prob01.sample) %>% as.data.frame() %>% mutate(Years="1981-2010", scenario="historical")
  results <-normals90.df 
  select.scenarios<- c( "ssp245", "ssp585")
  select.years.all <- c("_2011_2040", "_2041_2070", "_2071_2100")
  for(select.scenario in select.scenarios){
    for(years in select.years.all){
      climate90 <- rast(paste0(here("Data", "Spatial", "Downscaled"), "/ensemble_8GCMs_", select.scenario, years, "_90.tif"))[[pred.climate.vars]] 
       climate90 <- extract(climate90,  aspen90.prob01.sample)  %>% mutate(Years=years, scenario=select.scenario)
       results <- rbind(results, climate90)
    }
  }
    
  results <- results %>% pivot_longer(cols=all_of(pred.climate.vars))
  results$Years <- factor(results$Years, levels=c("1981-2010", "_2011_2040", "_2041_2070", "_2071_2100"), labels=c("1981-2010", "2011-2040", "2041-2070", "2071-2100"), ordered=T)
  results$scenario <- factor(results$scenario, levels=c("historical", "ssp245", "ssp585"), labels=c("historical", "SSP2-4.5", "SSP5-8.5"))
  results <- results %>% group_by(Years, scenario, name) %>% summarise(mean=mean(value, na.rm=T)) %>% filter(scenario %in% c("SSP5-8.5", "historical")) 
  results$X_vname_ <- results$name
  results$X_vname_ <- factor(results$X_vname_, levels=pred.vars)
  
  vip.glm <- read.csv(here("Results", "vip-glm.csv"))
  vip.rf <- read.csv(here("Results", "vip-rf.csv"))
  vip.xgb <- read.csv(here("Results", "vip-xgb.csv"))
  vip.gam <- read.csv(here("Results", "vip-gam.csv"))

  vip.dat <- rbind(vip.glm, vip.rf, vip.xgb, vip.gam)  %>% filter(!variable %in% c("_full_model_", "_baseline_", "aspen.prob", "x", "y", "cell")) %>% filter(variable %in% pred.vars)
  var.order <- vip.dat %>% group_by(variable) %>% summarise(mean=mean(dropout_loss)) %>% arrange(mean) %>% pull(variable)
  var.order.labs <- var.order
  var.order.labs[var.order.labs=="tpi3"] <- "TPI3"
  var.order.labs[var.order.labs=="hli"] <- "HLI"
  var.order.labs[var.order.labs=="clay"] <- "Clay"
  var.order.labs[var.order.labs=="thetas"] <- "SWC"
  vip.dat$variable <- factor(vip.dat$variable, levels=var.order, labels=var.order.labs, ordered=T)
  vip.dat <- vip.dat %>% filter(Model %in% ensemble.set)
  vip.dat$Model <- factor(vip.dat$Model, levels=c("GLM", "GAM", "RF", "XGB"), labels=c("GLM", "GAM", "RF", "RGBT"))

  
  p1 <- vip.dat %>%ggplot(aes(x=variable, y=dropout_loss, col=Model))+geom_boxplot()+coord_flip()+theme(legend.position="bottom")+theme(axis.title.y=element_blank(),legend.title = element_blank())+ylab("relative variable importance")+scale_color_cosmic()

  ale.glm <- read.csv(here("Results", "ale-GLM.csv"))
  ale.xgb <- read.csv(here("Results", "ale-xgb.csv"))
  ale.rf <- read.csv(here("Results", "ale-RF.csv"))
  ale.gam <- read.csv(here("Results", "ale-gam.csv"))
  ale.dat <- rbind(ale.glm, ale.xgb, ale.rf, ale.gam)
  ale.dat[ale.dat$X_vname_=="tpi3", "X_vname_"] <- "TPI3"
  ale.dat <- ale.dat %>% filter(Model %in% ensemble.set)
  ale.dat$Model <- factor(ale.dat$Model, levels=c("GLM", "GAM", "RF", "XGB"), labels=c("GLM", "GAM", "RF", "RGBT"))

  
  p2 <-  ale.dat %>% filter(X_vname_ %in% toupper(rev(var.order)[1:4]))  %>% ggplot( aes(x=X_x_,y=X_yhat_, col=Model)) +geom_line(show.legend = FALSE)+theme(legend.position="bottom")+ylab("probability of aspen presence")+xlab("value")+scale_color_cosmic()+facet_wrap(~X_vname_, scales="free_x",nrow=2)+geom_vline(data=results%>% filter(X_vname_ %in% rev(var.order)[1:4]), aes(xintercept=mean, lty=Years),linewidth=0.5)
  p12 <- p1+theme(legend.position = "none")+ p2 +plot_layout(nrow=1)+plot_annotation(tag_levels="A")+ plot_layout(guides = "collect") & theme(legend.position = 'bottom', legend.title = element_blank())
   ggsave(p12, filename=here("Results", "Figures", "vip-ale.jpg"), width=180, height=110, units="mm")
   
}

```

## Forcasting change in aspen habitat

To understand how future changes in climate may affect the distribution of aspen, we used the ensemble model to forecast the probability of aspen habitat suitability under the SSP2-4.5 and SSP5-8.5 scenarios for the 2011-2040, 2041-2070, and 2071-2100 periods. We then used these probabilistic forecasts of aspen habitat suitability to forecast aspen presence and absence based on the optimal probability threshold (see \@ref(model-ensemble)). We then overlaid forecasts of aspen presence-absence with the map of existing aspen occurrence from Cook et al. (in review) to produce maps where changes in climate may lead to aspen gain, loss, or stability. Finally, given expansion will be constrained by dispersal, we used a moving widow approach to calculate the distance to the nearest existing stand of aspen for each gain pixel. Specifically, we quantified the presence of aspen with 3, 5, 7, 13, 25, and 47 cell neighborhoods (i.e., within 90 m, 180 m, 270 m, 540 m, 1080 m, and 2070 m).

```{r GenFutureMap}
  pred19812010 <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"))  
  pred19812010[pred19812010>1] <- 1
  pred20112040 <- rast(here("Data", "Spatial", "Predictions","predicted_ensemble_8GCMs_ssp585_2011_2040-ensemble.tif"))
  pred20412070 <- rast(here("Data", "Spatial", "Predictions","predicted_ensemble_8GCMs_ssp585_2041_2070-ensemble.tif"))
  pred20712100 <- rast(here("Data", "Spatial", "Predictions","predicted_ensemble_8GCMs_ssp585_2041_2070-ensemble.tif"))
  
  study.area <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp"), quiet=T) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs(pred19812010)) 
  
  tm.19812010<-  tm_shape(pred19812010)+tm_raster(title="", palette="viridis")+tm_layout(main.title = "Current",main.title.size=1,main.title.position="center", bg.color="white", legend.position = c(0.01,0.725))+tm_shape(study.area) + tm_borders()
  
  tm.20112040<-  tm_shape(pred20112040)+tm_raster(title="", palette="viridis")+tm_layout(main.title = "2011-2040",main.title.size=1,main.title.position="center", bg.color="white",legend.show = FALSE)+tm_shape(study.area) + tm_borders()
  
  tm.20412070<-  tm_shape(pred20412070)+tm_raster(title="", palette="viridis")+tm_layout(main.title = "2041-2070",main.title.size=1,main.title.position="center", bg.color="white",legend.show = FALSE)+tm_shape(study.area) + tm_borders()
  
  tm.20712100<-  tm_shape(pred20712100)+tm_raster(title="", palette="viridis")+tm_layout(main.title = "2071-2100",main.title.size=1,main.title.position="center", bg.color="white", legend.show = FALSE)+tm_shape(study.area) + tm_borders()
  
  Fig.file <- here("Results", "Figures", "FigMaps-Change.jpg")
  jpeg(Fig.file, width=7, height=3.25, units="in", res=300)
  tmap_arrange(tm.19812010, tm.20112040, tm.20412070, tm.20712100, nrow=1)
  whatever <- dev.off()
```

```{r Change}
if(!file.exists(here("Results", "percent-change-meansd.csv"))){
  pred19812010 <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"))
pred19812010[pred19812010>1] <- 1
pred19812010.mean <- pred19812010%>% global(na.rm=T, fun="mean")
pred19812010.sd <- pred19812010%>% global(na.rm=T, fun="sd")
  
ssp245 <- list.files(here("Data", "Spatial", "Predictions"), pattern=glob2rx("predicted_ensemble_8GCMs_ssp245*-ensemble.tif"), full.names=T) %>% rast()
ssp245.pc <- (ssp245 - pred19812010) / pred19812010 *100
ssp245.mean <- ssp245.pc %>% global(na.rm=T, fun="mean")
ssp245.sd <- ssp245.pc %>% global(na.rm=T, fun="sd")

ssp585 <- list.files(here("Data", "Spatial", "Predictions"), pattern=glob2rx("predicted_ensemble_8GCMs_ssp585*-ensemble.tif"), full.names=T) %>% rast()
ssp585.pc <- (ssp585 - pred19812010) / pred19812010 *100
ssp585.mean <- ssp585.pc %>% global(na.rm=T, fun="mean")
ssp585.sd <- ssp585.pc %>% global(na.rm=T, fun="sd")
  
change.ssp245 <- data.frame(years=c("2011-2040", "2041-2070", "2071-2100"), mean=round(ssp245.mean$mean,1), sd=round(ssp245.sd$sd,1),scenario="SSP2-4.5")
change.ssp245 <- unite(change.ssp245, "value", mean:sd, sep=" ± ")

change.ssp585 <- data.frame(years=c( "2011-2040", "2041-2070", "2071-2100"), mean=round(ssp585.mean$mean,1), sd=round(ssp585.sd$sd,1),scenario="SSP5-8.5")
change.ssp585 <- unite(change.ssp585, "value", mean:sd, sep=" ± ")

change.dat <- rbind(change.ssp245, change.ssp585)
colnames(change.dat) <- c("years", "percent change", "scenario")

write.csv(change.dat, here("Results", "percent-change-meansd.csv"), row.names=F)
}


```

```{r TemporalPatterns, eval=F}
if(!file.exists(here("Data", "Spatial", "Predictions", "prob-change-predicted_ensemble_8GCMs_ssp245-ensemble.tif"))){
    aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
  names(aspen90.prob) <- "aspen.prob"
  aspen90.prob01 <- aspen90.prob
  aspen90.prob01[aspen90.prob01>0]<-1
  
  pred.1981_2010 <- rast(here("Data", "Spatial", "Predictions", "predicted_1981-2010-ensemble.tif"))
  
  ssp245.pred.2011_2040 <- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp245_2011_2040-ensemble.tif"))
  ssp245.pred.2041_2070 <- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp245_2041_2070-ensemble.tif"))
  ssp245.pred.2071_2100<- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp245_2071_2100-ensemble.tif"))
  ssp245.pred <- c(ssp245.pred.2011_2040, ssp245.pred.2041_2070,ssp245.pred.2071_2100)
  names(ssp245.pred) <- c("2011-2040", "2041-2070", "2071-2100")
  
  ssp585.pred.2011_2040 <- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp585_2011_2040-ensemble.tif"))
  ssp585.pred.2041_2070 <- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp585_2041_2070-ensemble.tif"))
  ssp585.pred.2071_2100<- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp585_2071_2100-ensemble.tif"))
  ssp585.pred <- c(ssp585.pred.2011_2040 , ssp585.pred.2041_2070, ssp585.pred.2071_2100)
  names(ssp585.pred) <- c("2011-2040", "2041-2070", "2071-2100")
  
  ssp245.pred.continuous.change <- ssp245.pred - pred.1981_2010
  writeRaster(ssp245.pred.continuous.change, here("Data", "Spatial", "Predictions", "prob-change-predicted_ensemble_8GCMs_ssp245-ensemble.tif"), overwrite=T)
  
  ssp585.pred.continuous.change <-ssp585.pred - pred.1981_2010
  writeRaster(ssp585.pred.continuous.change, here("Data", "Spatial", "Predictions", "prob-change-predicted_ensemble_8GCMs_ssp585-ensemble.tif"), overwrite=T)
}

ssp585.pred.continuous.change <- rast(here("Data", "Spatial", "Predictions", "prob-change-predicted_ensemble_8GCMs_ssp585-ensemble.tif"))
change.dat.ssp245 <- ssp245.pred.continuous.change %>% spatSample(size=10000,na.rm=T) %>% mutate(scenario="ssp245") %>% pivot_longer(-scenario)
change.dat.ssp585 <- ssp585.pred.continuous.change %>% spatSample(size=10000,na.rm=T) %>% mutate(scenario="ssp585") %>% pivot_longer(-scenario)
change.dat <- rbind(change.dat.ssp245, change.dat.ssp585)
change.dat$scenario <- factor(change.dat$scenario, levels=c("ssp245", "ssp585"), labels=c("SSP2-4.5", "SSP5-8.5"))
p1 <- ggplot(change.dat, aes(x=name, y=value, col=scenario))+geom_boxplot(outlier.size = 0.5)+ylab("change in the probability\nof aspen presence")+xlab("time period")+scale_colour_manual(values=c( "#1b9e77", "#7570b3"))+theme(legend.title=element_blank(), legend.position = "bottom")
ggsave(p1, filename=here("Results", "Figures", "change-probability.jpg"), width=90, height=70, units="mm")

# Categorical
if(!file.exists(here("Data", "Spatial", "Predictions","pa-change_ensemble_8GCMs_ssp245-ensemble.tif"))){
  read.csv(here("Results", "Ensemble-prediction-threshold.csv")) %>% 
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold) -> threshold.ensemble

  pred.1981_2010.cat <- pred.1981_2010
  pred.1981_2010.cat[pred.1981_2010.cat<threshold.ensemble]<-0
  pred.1981_2010.cat[pred.1981_2010.cat>=threshold.ensemble] <-1
  
  ssp245.pred.cat <- ssp245.pred
  ssp245.pred.cat[ssp245.pred.cat<threshold.ensemble]<-0
  ssp245.pred.cat[ssp245.pred.cat>=threshold.ensemble]<-1
  
  ssp585.pred.cat <- ssp585.pred
  ssp585.pred.cat[ssp585.pred.cat<threshold.ensemble]<-0
  ssp585.pred.cat[ssp585.pred.cat>=threshold.ensemble]<-1
  
  change.ssp245 <- pred.1981_2010.cat
  change.ssp245[change.ssp245==1] <- 10
  change.ssp245 <- change.ssp245 - ssp245.pred.cat
  change.ssp245[change.ssp245==-1] <- 2 # gain
  change.ssp245[change.ssp245==10] <- -1 # loss
  change.ssp245[change.ssp245==9] <- 1 # stable
  names(change.ssp245) <- c("2011-2040", "2041-2070", "2071-2100")
  writeRaster(change.ssp245, here("Data", "Spatial", "Predictions","pa-change_ensemble_8GCMs_ssp245-ensemble.tif"), overwrite=T)
  
  change.ssp585 <- pred.1981_2010.cat
  change.ssp585[change.ssp585==1] <- 10
  change.ssp585 <- change.ssp585 - ssp585.pred.cat
  change.ssp585[change.ssp585==-1] <- 2 # gain
  change.ssp585[change.ssp585==10] <- -1 # loss
  change.ssp585[change.ssp585==9] <- 1 # stable
  names(change.ssp585) <- c("2011-2040", "2041-2070", "2071-2100")
  writeRaster(change.ssp585, here("Data", "Spatial", "Predictions", "pa-change_ensemble_8GCMs_ssp585-ensemble.tif"), overwrite=T)
}
change.ssp245 <- rast(here("Data", "Spatial", "Predictions", "pa-change_ensemble_8GCMs_ssp245-ensemble.tif"))
change.ssp585 <- rast(here("Data", "Spatial", "Predictions", "pa-change_ensemble_8GCMs_ssp585-ensemble.tif"))
change.ssp245.f <- freq(change.ssp245) %>% mutate(layer=factor(layer, levels=1:3, labels=names(change.ssp245)), scenario="ssp245")
change.ssp585.f <- freq(change.ssp585) %>% mutate(layer=factor(layer, levels=1:3, labels=names(change.ssp585)), scenario="ssp585")
change.f <- rbind(change.ssp245.f, change.ssp585.f) %>% filter(!value==0)
change.f$var <- factor(change.f$value, levels=c(-1,1,2),labels=c("loss", "stable", "gain"))
change.f$area <- change.f$count*90*90*10^-6
p2 <- ggplot(change.f, aes(x=layer, y=area,fill=scenario))+geom_bar(stat="identity", position="dodge")+theme(legend.title=element_blank(), legend.position="right")+ylab("area (sq. km)")+scale_fill_manual(values=c( "#1b9e77", "#7570b3"))+facet_wrap(~var, scales="free_y", nrow=3)+xlab("time period")
ggsave(p2, filename=here("Results", "Figures", "loss-gain.jpg"), width=90, height=90, units="mm")


area.1981.2010 <- freq(pred.1981_2010) %>% filter(value==1) %>% pull(count)


area.ssp245.2011_2040 <- freq(ssp245.pred.2011_2040) %>% filter(value==1) %>% pull(count)
area.ssp245.2041_2070<- freq(ssp245.pred.2041_2070) %>% filter(value==1) %>% pull(count)
area.ssp245.2071_2100<- freq(ssp245.pred.2071_2100) %>% filter(value==1) %>% pull(count)
area.ssp245 <- data.frame( year=c("1981-2010", "2011-2040", "2041-2070", "2071-2100"), scenario="ssp245", area=c(area.1981.2010, area.ssp245.2011_2040, area.ssp245.2041_2070, area.ssp245.2071_2100))


area.ssp585.2011_2040 <- freq(ssp585.pred.2011_2040) %>% filter(value==1) %>% pull(count)
area.ssp585.2041_2070<- freq(ssp585.pred.2041_2070) %>% filter(value==1) %>% pull(count)
area.ssp585.2071_2100<- freq(ssp585.pred.2071_2100) %>% filter(value==1) %>% pull(count)
area.ssp585 <- data.frame( year=c("1981-2010","2011-2040", "2041-2070", "2071-2100"), scenario="ssp585", area=c(area.1981.2010,area.ssp585.2011_2040, area.ssp585.2041_2070, area.ssp585.2071_2100))

area.df <- rbind( area.ssp245, area.ssp585)
area.df$area <- 90*90 * area.df$area *10^-6
area.df$year <- factor(area.df$year, ordered=T)
area.df$scenario <- factor(area.df$scenario, levels=c("ssp245", "ssp585"), labels=c("SSP2-4.5", "SSP5-8.5"))


  p1 <- ggplot(area.df, aes(x=year, y=area, col=scenario, group=scenario))+geom_line()+geom_point()+ylab("area suitable\nfor aspen (sq. km)")+theme(legend.position="bottom", legend.title=element_blank())+xlab("time period")+scale_colour_manual(values=c( "#1b9e77", "#7570b3"))
  ggsave(p1, filename=here("Results", "Figures", "area-timeseries.jpg"), width=90, height=60, units="mm")
```

```{r CompositeLossGain}
if(!file.exists(here("Data", "Spatial", "Predictions", "lossgain-ssp245.tif"))){
  aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
  names(aspen90.prob) <- "aspen.prob"
  aspen90.prob01 <- aspen90.prob
  aspen90.prob01[aspen90.prob01>0]<-1
  
  read.csv(here("Results", "Ensemble-prediction-threshold.csv")) %>% 
    filter(.metric == "j_index") %>%
    filter(.estimate == max(.estimate)) %>%
    pull(.threshold) -> threshold.ensemble
  
  ssp245.pred.2011_2040 <- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp245_2011_2040-ensemble.tif"))
  ssp245.pred.2041_2070 <- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp245_2041_2070-ensemble.tif"))
  ssp245.pred.2071_2100<- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp245_2071_2100-ensemble.tif"))
  ssp245.pred <- c(ssp245.pred.2011_2040, ssp245.pred.2041_2070,ssp245.pred.2071_2100)
  names(ssp245.pred) <- c("2011-2040", "2041-2070", "2071-2100")
  ssp245.pred.cat <- ssp245.pred
  ssp245.pred.cat[ssp245.pred.cat<threshold.ensemble]<-0
  ssp245.pred.cat[ssp245.pred.cat>=threshold.ensemble]<-10
  ssp245.pred.cat <- ssp245.pred.cat + aspen90.prob01
  #0 = not suitable
  #1 = loss
  #10 = gain
  # 11 = stable
  writeRaster(ssp245.pred.cat, here("Data", "Spatial", "Predictions", "lossgain-ssp245.tif"), overwrite=T)
}

if(!file.exists(here("Data", "Spatial", "Predictions", "lossgain-ssp585.tif"))){
  aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
  names(aspen90.prob) <- "aspen.prob"
  aspen90.prob01 <- aspen90.prob
  aspen90.prob01[aspen90.prob01>0]<-1
  
  read.csv(here("Results", "Ensemble-prediction-threshold.csv")) %>% 
    filter(.metric == "j_index") %>%
    filter(.estimate == max(.estimate)) %>%
    pull(.threshold) -> threshold.ensemble
  
  ssp585.pred.2011_2040 <- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp585_2011_2040-ensemble.tif"))
  ssp585.pred.2041_2070 <- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp585_2041_2070-ensemble.tif"))
  ssp585.pred.2071_2100<- rast(here("Data", "Spatial", "Predictions", "predicted_ensemble_8GCMs_ssp585_2071_2100-ensemble.tif"))
  ssp585.pred <- c(ssp585.pred.2011_2040, ssp585.pred.2041_2070,ssp585.pred.2071_2100)
  names(ssp585.pred) <- c("2011-2040", "2041-2070", "2071-2100")
  ssp585.pred.cat <- ssp585.pred
  ssp585.pred.cat[ssp585.pred.cat<threshold.ensemble]<-0
  ssp585.pred.cat[ssp585.pred.cat>=threshold.ensemble]<-10
  ssp585.pred.cat <- ssp585.pred.cat + aspen90.prob01
  #0 = not suitable
  #1 = loss
  #10 = gain
  # 11 = stable
  writeRaster(ssp585.pred.cat, here("Data", "Spatial", "Predictions", "lossgain-ssp585.tif"), overwrite=T)
}

ssp245<- rast(here("Data", "Spatial", "Predictions", "lossgain-ssp245.tif"))
ssp245 <- subst(ssp245, 0, NA)
ssp585<- rast(here("Data", "Spatial", "Predictions", "lossgain-ssp585.tif"))
ssp585 <- subst(ssp585, 0, NA)

loss.gain.freq.ssp585 <-  ssp585 %>% freq() %>% mutate(scenario="SSP5-8.5")
loss.gain.freq.ssp245 <-  ssp245 %>% freq() %>% mutate(scenario="SSP2-4.5")
loss.gain.freq <- rbind(loss.gain.freq.ssp245,loss.gain.freq.ssp585)
colnames(loss.gain.freq) <- c("years", "status", "count", "scenario")
loss.gain.freq$years <- factor(loss.gain.freq$years, levels=1:3, labels=c("2011-2040", "2041-2070", "2071-2100"))
loss.gain.freq$status <- factor(loss.gain.freq$status, levels=c(1,10,11), labels=c("loss", "gain", "stable"))
loss.gain.freq$area <- round(loss.gain.freq$count * 90*90 *10^-6, 0)
write.csv(loss.gain.freq, here("results", "loss-gain.csv"),row.names=F)

tm.ssp245<- tm_shape(study.area)+tm_fill(col="grey25") + tm_shape(ssp245[[3]])+tm_raster( style= "cat", title="", labels=c("loss", "gain", "stable"), palette=c("#fdc086","#386cb0", "#7fc97f"))+tm_layout(main.title = "SSP2-4.5",main.title.size=1,main.title.position="center", bg.color="white", legend.position = c(0.01,0.8))+tm_shape(study.area) +tm_borders()

tm.ssp585<- tm_shape(study.area)+tm_fill(col="grey25")+tm_shape(ssp585[[3]])+tm_raster( style= "cat", title="", labels=c("loss",  "gain", "stable"), palette=c("#fdc086","#386cb0", "#7fc97f"), legend.show = FALSE)+tm_layout(main.title = "SSP5-8.5",main.title.size=1,main.title.position="center", bg.color="white",legend.show = FALSE)+tm_shape(study.area) + tm_borders()

Fig.file <- here("Results", "Figures", "FigMaps-LossGain.jpg")
  jpeg(Fig.file, width=3.5, height=3.25, units="in", res=300)
  tmap_arrange(tm.ssp245, tm.ssp585, nrow=1)
whatever <- dev.off()

Fig.file <- here("Results", "Figures", "FigMaps-LossGain1.jpg")
  jpeg(Fig.file, width=3.5, height=5, units="in", res=300)
  tm_shape(study.area)+tm_fill(col="grey25") + tm_shape(ssp245[[3]])+tm_raster( style= "cat", title="", labels=c("loss", "gain", "stable"), palette=c("#fdc086","#386cb0", "#7fc97f"))+tm_layout(main.title = "",main.title.size=1,main.title.position="center", bg.color="white", legend.position = c(0.01,0.9))+tm_shape(study.area) +tm_borders()+ tm_compass( position=c("right", "top"))+ tm_scale_bar(position=c("left", "bottom"))
whatever <- dev.off()


##  Spatial patterns
if(!file.exists(here("Results", "Figures", "gainloss-geography.jpg"))){
  elev <- rast(here("Data", "Spatial", "DEM", "DEM250.tif"))
  aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
  pts <- ssp245 %>%  spatSample(size=5000,na.rm=T, method="stratified", as.points=T, exhaustive=T)
  pts <- extract(ssp245, pts, bind=T)
  pts <- extract(ssp585, pts, bind=T) 
  pts <- extract(aspen90.prob, pts, bind=T) %>% terra::project(crs(elev))
  pts <- extract(elev, pts, bind=T, spatial=T)
  pts.coords <- crds(pts %>% terra::project('EPSG:4326') , df=T)
  
  dat <- cbind(as.data.frame(pts)[,-1], pts.coords)
  dat$x <- dat$x *-1
  colnames(dat) <- c(paste("SSP2-4.5", c("2011-2040", "2041-2070","2071-2100"), sep=":"), paste("SSP5-8.5", c("2011-2040", "2041-2070","2071-2100"), sep=":"), "Percent\naspen", "Elevation\n(m)", "Longitude\n(°W)","Latitude\n(°N)")
  dat$`Percent\naspen` <- dat$`Percent\naspen`*100
  
  
  dat <- pivot_longer(dat,
      cols = 'SSP2-4.5:2011-2040':'SSP5-8.5:2071-2100', 
      names_to = "time period",
      values_to = "value"
  )
  
  dat$scenario <- sapply(strsplit(dat$`time period`, split=":"), "[", 1)
  dat$`time period` <- sapply(strsplit(dat$`time period`, split=":"), "[", 2)
  dat$value <- factor(dat$value, levels=c(1,11,10), labels=c("loss", "gain","stable"), ordered=T)
  
  datx <- pivot_longer(dat,
      cols = `Percent\naspen`:`Latitude\n(°N)`, 
      names_to = "variable",
      values_to = "val"
  )
  datx$`time period` <- factor(datx$`time period`, levels=c("2011-2040", "2041-2070","2071-2100"), labels=c("2011-\n2040", "2041-\n2070","2071-\n2100"))
  datx <- datx %>% na.omit()
  p1<-ggplot(datx, aes(x=`time period`, y=val,fill=value))+geom_boxplot(outlier.size = 0.5)+facet_grid(variable~scenario, scales="free")+theme(legend.position="bottom", legend.title=element_blank())+ylab("value")+scale_fill_manual(values=c("#fdc086","#386cb0", "#7fc97f"))
  
  ggsave(p1, filename=here("Results", "Figures", "gainloss-geography.jpg"), width=90, height=110, units="mm")  
}
```

```{r GainDistance}
aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
names(aspen90.prob) <- "aspen.prob"
aspen90.prob01 <- aspen90.prob
aspen90.prob01[aspen90.prob01>0]<-1

windowz <- c(3, 5, 7, 13, 25, 47)
if(!dir.exists(here("Data", "Spatial", "Aspen", "Focal"))){
  dir.create(here("Data", "Spatial", "Aspen", "Focal"))
  for(win in windowz){
    aspen90.focal <- focal(aspen90.prob01, w=win, fun=max, na.policy="omit", filename=here("Data", "Spatial", "Aspen", "Focal", paste0("aspen-", win, ".tif")))
  }
  focal.sum<- list.files(here("Data", "Spatial", "Aspen", "Focal"), full.names=T) %>% rast() %>% sum()
  writeRaster(focal.sum, filename=here("Data", "Spatial", "Aspen", "Focal","Aspen-sum.tif"))
}

focal.sum <- rast(here("Data", "Spatial", "Aspen", "Focal","Aspen-sum.tif"))
focal.sum[focal.sum==0] <- -1

read.csv(here("Results", "Ensemble-prediction-threshold.csv")) %>% 
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold) -> threshold.ensemble

ssp245<- rast(here("Data", "Spatial", "Predictions", "lossgain-ssp245.tif"))
ssp245 <- subst(ssp245, c(0,1,11), NA)
ssp585<- rast(here("Data", "Spatial", "Predictions", "lossgain-ssp585.tif"))
ssp585 <- subst(ssp585, c(0,1,11), NA)
 
ssp245.dist <-  ssp245 * focal.sum 
ssp585.dist <-  ssp585* focal.sum 
writeRaster(ssp245.dist, here(here("Data", "Spatial", "Predictions", "ssp245-gain-distance.tif")), overwrite=T)
writeRaster(ssp585.dist, here(here("Data", "Spatial", "Predictions", "ssp585-gain-distance.tif")), overwrite=T)
  
ssp245.dist <- rast(here("Data", "Spatial", "Predictions", "ssp245-gain-distance.tif"))
ssp585.dist <- rast(here("Data", "Spatial", "Predictions", "ssp585-gain-distance.tif"))

ssp245dat <- ssp245.dist %>% freq() %>% filter(!value==0) %>% group_by(layer) %>% mutate(prop=count/sum(count), scenario="SSP2-4.5")
ssp585dat <- ssp585.dist %>% freq() %>% filter(!value==0) %>% group_by(layer) %>% mutate(prop=count/sum(count), scenario="SSP5-8.5")
  
 dist.dat <- rbind(ssp245dat, ssp585dat) %>% mutate(years = factor(layer, levels=1:3, labels=c("2011-2040", "2041-2070", "2071-2100")), distance=factor(value/10, levels=c(1:6, -1), labels=c("90", "180", "270", "540", "1080", "2070", ">2070")) )
  
  write.csv(dist.dat, here("Results", "distance.csv"), row.names=F)
  
  p1 <- ggplot(dist.dat, aes(x=distance, y=prop, fill=scenario))+geom_bar(stat="identity", position="dodge")+facet_wrap(~years, nrow=3)+theme(legend.position = "bottom")+scale_fill_manual(values=c( "#1b9e77", "#7570b3"))+xlab("distance (m)")+ylab("proportion")
  
ggsave(p1, filename=here("Results", "Figures", "gaindist-geography.jpg"), width=90, height=150, units="mm")  

  
tm.ssp245<- tm_shape(study.area)+tm_fill(col="grey95") +tm_shape(ssp245.dist[[3]])+tm_raster( style= "cat", title="", labels=c("90", "180", "270", "540", "1080", "2070", ">2070"), palette=c("#fde725", "#a0da39", "#4ac16d", "#1fa187","#277f8e", "#365c8d", "#46327e"))+tm_layout(main.title = "SSP2-4.5",main.title.size=1,main.title.position="center", bg.color="white",legend.position = c(0.01,0.625))+tm_shape(study.area) + tm_borders()
  
tm.ssp585<- tm_shape(study.area)+tm_fill(col="grey95")+tm_shape(ssp585.dist[[3]])+tm_raster( style= "cat", title="", labels=c("90", "180", "270", "540", "1080", "2070", ">2070"), palette=c("#fde725", "#a0da39", "#4ac16d", "#1fa187","#277f8e", "#365c8d", "#46327e"), legend.show = FALSE)+tm_layout(main.title = "SSP5-8.5",main.title.size=1,main.title.position="center", bg.color="white",legend.show = FALSE)+tm_shape(study.area) + tm_borders()


Fig.file <- here("Results", "Figures", "FigMaps-Gain-Distance.jpg")
  jpeg(Fig.file, width=3.5, height=3.25, units="in", res=300)
  tmap_arrange(tm.ssp245, tm.ssp585, nrow=1)
whatever <- dev.off()

Fig.file <- here("Results", "Figures", "FigMaps-Gain-Distance1.jpg")
  jpeg(Fig.file, width=3.5, height=5, units="in", res=300)
   tm_shape(study.area)+tm_fill(col="grey95") +tm_shape(ssp245.dist[[3]])+tm_raster( style= "cat", title="", labels=c("90", "180", "270", "540", "1080", "2070", ">2070"), palette=c("#fde725", "#a0da39", "#4ac16d", "#1fa187","#277f8e", "#365c8d", "#46327e"))+tm_layout(main.title = "",main.title.size=1,main.title.position="center", bg.color="white", legend.position = c(0.01,0.78))+tm_shape(study.area) +tm_borders()+ tm_compass( position=c("right", "top"))+ tm_scale_bar(position=c("left", "bottom"))
whatever <- dev.off()


```

# Results

## Model performance

```{r ModPerformance}
glm.train.perfom <- read.csv(here("Results", "glm-training-stats.csv"))
xgb.train.perfom <- read.csv(here("Results", "xgb-training-stats.csv"))
rf.train.perfom <- read.csv(here("Results", "RF-training-stats.csv"))
gam.train.perfom <- read.csv(here("Results", "GAM-training-stats.csv"))
train.perform <- do.call(rbind, list(glm.train.perfom,xgb.train.perfom,rf.train.perfom,gam.train.perfom ))%>% mutate(mean=round(mean, 2), std_err=round(std_err,2)) 
train.perform$mean<- paste0(train.perform$mean, " ± ") 
train.perform$.estimate <- do.call(paste0, train.perform[,c("mean", "std_err")])

train.results <- train.perform %>%  select(-X, -.estimator, -std_err, -.config, -Dataset, -n, -mean)  %>% spread(.metric, .estimate)
colnames(train.results) <- c("Model", "Accuracy", "F measure", "kappa", "Precision", "Recall", "AUC", "Sensitivity", "Specificity")
train.results$Model <- factor(train.results$Model, levels=c("GLM", "GAM", "RF", "XGB"), labels=c("GLM", "GAM", "RF", "GBT"))

test.results <- read.csv(here("results", "training-accuracy-stats-combined.csv")) %>% mutate(.estimate=round(.estimate, 2)) %>% select(-X, -.estimator) %>% spread(.metric, .estimate)
colnames(test.results) <- c("Model", "Accuracy", "F measure", "kappa", "Precision", "Recall", "AUC", "Sensitivity", "Specificity")
test.results <- test.results %>% filter(Model %in% c(ensemble.set, "Ensemble"))

photo.results <- read.csv(here("results", "photo-accuracy-combined.csv")) %>% mutate(percent=round(percent*100,0))

missclass.dat <- read.csv(here("Results", "misclass-dat.csv"))

```

<<<<<<< HEAD
Spatial cross-validation revealed all models accurately predicted to new areas; across the five folds the mean AUC statistic (± standard error of the mean) was `r train.results %>% filter(Model=="GLM") %>% pull(AUC)`, `r train.results %>% filter(Model=="GAM") %>% pull(AUC)`, `r  train.results %>% filter(Model=="RF") %>% pull(AUC)` `r train.results %>% filter(Model=="GBT") %>% pull(AUC)`, for the GLM, GAM, RF, and RGBT, respectively. When compared with the testing data, all models achieved an AUC greater than 0.8, indicating a good model fit (Table \@ref(tab:PerformanceTab)). Tree-based approaches were generally better than the GLM or GAM at predicting aspen presence (i.e., higher sensitivity), but were worse at predicting aspen absence (i.e. lower specificity). Based on AUC, the ensemble model outperformed each individual model, however the improvement was minimal (Table \@ref(tab:PerformanceTab)). When compared aspen with an independent dataset of aspen presence derived from aerial photo interpretation, the ensemble model correctly predicted `r photo.results %>% filter(model=='Ensemble') %>% pull(percent)`% of points (n=\`r photo.results `%>% filter(model=='Ensemble') %>% pull(n)).`
=======
Spatial cross-validation revealed all models accurately predicted to new areas; across the five folds the mean AUC statistic (± standard error of the mean) was `r train.results %>% filter(Model=="GLM") %>% pull(AUC)`, `r train.results %>% filter(Model=="GAM") %>% pull(AUC)`, `r  train.results %>% filter(Model=="RF") %>% pull(AUC)` `r train.results %>% filter(Model=="GBT") %>% pull(AUC)`, for the GLM, GAM, RF, and RGBT, respectively. When compared with the testing data, all models achieved an AUC greater than 0.8, indicating a good model fit (Table \@ref(tab:PerformanceTab)). Tree-based approaches were generally better than the GLM or GAM at predicting aspen presence (i.e., higher sensitivity), but were worse at predicting aspen absence (i.e., lower specificity). Based on AUC, the ensemble model outperformed each individual model, however the improvement was minor (Table \@ref(tab:PerformanceTab)). When compared aspen with an independent dataset of aspen presence derived from aerial photo interpretation, the ensemble model correctly predicted `r photo.results %>% filter(model=='Ensemble') %>% pull(percent)`% of points (n=`r photo.results %>% filter(model=='Ensemble') %>% pull(n)`).
>>>>>>> master

```{r PerformanceTab}
test.results %>%  flextable() %>% set_caption(caption="Model performance statistics. Observed values are from independent testing data.") %>% autofit() %>% set_table_properties(layout = "autofit")
```

While the ensemble model performed well, there were spatial patterns in the residuals (Fig. \@ref(fig:MissClassMap) and \@ref(fig:MissClassBoxPlot)). Relative to true positives (i.e., pixels where aspen was present that were correctly classified), false negatives (i.e., pixels where aspen was present but the model predicted absence) were concentrated at lower elevations and more eastern latitudes, while false positives (i.e., pixels where aspen was absent but the model predicted presence) occurred more frequently at higher elevations and more western latitudes. False negatives were common where the percent aspen cover within the 90 x 90 m pixel was low (median value of `r missclass.dat %>% filter(Class=="false\nnegative", variable=="Percent aspen") %>% pull(median) %>% round(1)`%).

```{r MissClassBoxPlot, fig.cap="Boxplots illustrating the relationship between pixels missclassified and geographic variables and percent aspen cover.", out.width="90mm", out.height="100mm"}
knitr::include_graphics(here("Results", "Figures", "missclass-geography.jpg"), dpi=NA)
```

## Effects of predictor variables on aspen habitat suitability

<<<<<<< HEAD
Variable importance scores illustrated the effects of regularization, which were included in the GLM and GAM and allowed for coefficient estimates to shrink to zero. In these models fewer variables contributed to the predicting aspen presence (Fig. \@ref(fig:VIPFig)A)). Across all models, variable importance scores revealed that climate variables generally contributed more to model fit than soil or topographic factors (Fig. \@ref(fig:VIPFig)A)). ADI was on average the most important predictor (Fig. \@ref(fig:VIPFig)A). Future increases in ADI over the next century, will likely lead to a decrease in mean aspen habitat suitability Fig. \@ref(fig:VIPFig)B). However, the GLM suggested that future increases in ADI may initially lead to an increase in mean aspen habitat suitability, followed by a decrease by 2071-2100. PRATIO was the second most important predictor on average (Fig. \@ref(fig:VIPFig)A). Decreases in PRATIO over the next 100 years (Fig. \@ref(fig:VIPFig)B), will likely lead to an increase in aspen habitat suitability across the SRM. However, for locations where PRATIO is already low, the GAM, RF, and RGBT models suggest this may decrease aspen habitat suitability. GSPDD5 was identified as a particularly important predictor variable in the GAM (Fig. \@ref(fig:VIPFig)A). Across the study area GSPDD5 is expected to decrease over the next century, largely due to increases in temperature (Fig. \@ref(fig:VIPFig)B). Our SDMs suggest this may lead to a decrease, increase, or no change in mean aspen habitat suitability across the SRM. In the GAM GSPDD5 is negatively associated with aspen presence, while GSPDD5 had no effect in the GLM, and the relationship was more hump-shaped in RF and RGBT models. All models suggested that aspen habitat suitability was higher in valley bottoms (low TPI3) than steep slopes (high TPI3), although RF and RGBT models suggested benches (moderate TPI3) may be equally suitable as steep slopes (Fig. \@ref(fig:VIPFig)B).
=======
Variable importance scores illustrated the effects of regularization, which allowed coefficient estimates in the GLM and GAM to shrink to zero. In these models fewer variables contributed to the predicting aspen presence (Fig. \@ref(fig:VIPFig)A). Nonetheless, we found that for all models climate variables generally contributed more to model fit than soil or topographic factors (Fig. \@ref(fig:VIPFig)A). On average, ADI was on average the most important predictor, according to variable importance scores (Fig. \@ref(fig:VIPFig)A). Future increases in ADI over the next century, will likely lead to a decrease in mean aspen habitat suitability (Fig. \@ref(fig:VIPFig)B). However, the GLM suggested that future increases in ADI may initially lead to an increase in mean aspen habitat suitability, followed by a decrease by 2071-2100. PRATIO was the second most important predictor on average (Fig. \@ref(fig:VIPFig)A). Decreases in PRATIO over the next 100 years (Fig. \@ref(fig:VIPFig)B), will likely lead to an increase in aspen habitat suitability across the SRM. However, for locations where PRATIO is already low, the GAM, RF, and RGBT models suggest this may decrease aspen habitat suitability. Across the study area GSPDD5 is expected to decrease over the next century, largely due to increases in temperature (Fig. \@ref(fig:VIPFig)B). Our SDMs suggest this may lead to a decrease, increase, or no change in mean aspen habitat suitability across the SRM. In the GAM, GSPDD5 is negatively associated with aspen presence, while GSPDD5 had no effect in the GLM, and the relationship was more hump-shaped in RF and RGBT models. All models suggested that aspen habitat suitability was higher in valley bottoms (low TPI3) than steep slopes (high TPI3), although RF and RGBT models suggested benches (moderate TPI3) may be equally suitable as steep slopes (Fig. \@ref(fig:VIPFig)B).
>>>>>>> master

```{r VIPFig, fig.cap="Variable importance scores (A) and accumulate local effects (B) for models of aspen habitat suitability by modeling approach. In A, boxes illustrate the loss in model performance (1-AUC) when the predcitor variable was been randomized for 10 different permutations. In B, vertical lines illustrate the mean climate conditions for areas with existing aspen for the historical period (1981-2010) and projections for the 2011-2040, 2041-2070, and 2071-2100 periods under the SPP4-8.5 scenario. For variable definitions and descriptions see Table 1.", out.width="180mm", out.height="110mm"}
knitr::include_graphics(here("Results", "Figures", "vip-ale.jpg"), dpi = NA)
```

## Forecasted change in the distribution of aspen

```{r}
pchange.dat <- read.csv(here("Results", "percent-change-meansd.csv"))
lg.freq <- read.csv(here("results", "loss-gain.csv"))
dist.dat <- read.csv( here("Results", "distance.csv"))

read.csv(here("Results", "ensemble-prediction-threshold.csv")) %>%
  filter(.metric == "j_index") %>%
  filter(.estimate == max(.estimate)) %>%
  pull(.threshold) -> threshold.ensemble
```

Our ensemble SDM forecasts notable decreases in future aspen habit suitability with particularly dramatic decreases predicted to occur within the first half of the 21st century. Under the SSP2-4.5 scenario, the ensemble model suggests a percent change in the mean probability of aspen of `r pchange.dat %>% filter(years=="2011-2040" & scenario =="SSP2-4.5") %>% pull(percent.change)`% by 2040 and `r pchange.dat %>% filter(years=="2071-2100" & scenario =="SSP2-4.5") %>% pull(percent.change)`% by 2100. Under the SSP5-8.5 scenario, our model forecasts similar reductions on average, but more variable responses across the study area. The predicted percent change in the mean probability of aspen was `r pchange.dat %>% filter(years=="2011-2040" & scenario =="SSP5-8.5") %>% pull(percent.change)`% for the 2011-2040 period and `r pchange.dat %>% filter(years=="2071-2100" & scenario =="SSP5-8.5") %>% pull(percent.change)`% for the 2071-2100 period.

Based on the `r threshold.ensemble` probability threshold for classifying aspen occurrence, which was selected based on Youden's J statistic (\@ref(model-ensemble)), our ensemble SDM suggests that decreases in the aspen habitat suitability may result in the loss of aspen across `r lg.freq %>% filter(status=="loss" & years == "2071-2100" & scenario=="SSP2-4.5") %>% pull(area)` km^2^ under the SSP2-4.5 scenario and `r lg.freq %>% filter(status=="loss" & years == "2071-2100" & scenario=="SSP5-8.5") %>% pull(area)` km^2^ under the SSP5-8.5 scenario by 2100 (Fig. \@ref(fig:LossGainMaps)). However, the decrease in the area suitable for aspen may be offset by increases in the area suitable for aspen. By 2100, the ensemble model suggests an increase in the area suitable for aspen of `r lg.freq %>% filter(status=="gain" & years == "2071-2100" & scenario=="SSP2-4.5") %>% pull(area)` and `r lg.freq %>% filter(status=="gain" & years == "2071-2100" & scenario=="SSP5-8.5") %>% pull(area)` km^2^ under the SSP2-4.5 and SSP5-8.5 scenarios, respectively. Across both scenarios and all time periods, losses in the area suitable for aspen are forecasted to occur at lower elevations and eastern latitudes, where aspen is already limited (Figs. \@ref(fig:LossGainBox) and \@ref(fig:LossGainMaps)). Increases in the area suitable for aspen are forecasted to occur at higher elevations.

```{r LossGainBox, fig.cap="Boxplots illustrating spatial patterns in the areas were aspen my lost, gained, or remain stable based on the ensemeble SDM's forecast of future aspen habitat suitability.", out.width="90mm", out.height="110mm"}
knitr::include_graphics(here("Results", "Figures", "gainloss-geography.jpg"), dpi = NA)
```

While the area suitable for aspen is expected to increases substantially, only a fraction of that area is near existing aspen stands (Fig. \@ref(fig:GainDistanceGeo) and \@ref(fig:GainDistanceMaps,)). Under the SSP4-2.5 scenario, `r  (dist.dat %>% filter(scenario=="SSP2-4.5" & years=="2071-2100" & distance =="90") %>% pull(prop)*100) %>% round()` % of the area forecasted to become suitable by 2071-2100 is within 90-m of existing aspen (Fig. \@ref(fig:GainDistanceGeo)), and `r  (dist.dat %>% filter(scenario=="SSP2-4.5" & years=="2071-2100" & distance %in% c("90", "180", "270", "540")) %>% pull(prop) %>% sum()*100) %>% round()`% of the suitable area is within 540-m of existing aspen. Under the SSP5-8.5 scenario, `r  (dist.dat %>% filter(scenario=="SSP5-8.5" & years=="2071-2100" & distance =="90") %>% pull(prop)*100) %>% round()` % of the area forecasted to become suitable by 2071-2100 is within 90-m of existing aspen (Fig. \@ref(fig:GainDistanceGeo)), and `r  (dist.dat %>% filter(scenario=="SSP5-8.5" & years=="2071-2100" & distance %in% c("90", "180", "270", "540")) %>% pull(prop) %>% sum()*100) %>% round()`% of the suitable area is within 540-m of existing aspen. 

```{r GainDistanceGeo, fig.cap="The distance to the nearest existing aspen patch for pixels where changes in climate may promote aspen expansion.", out.width="90mm", out.height="150mm"}
knitr::include_graphics(here("Results", "Figures", "gaindist-geography.jpg"), dpi = NA)
```

# Discussion

1.  Overview of results
2.  Discussion of comparison with previous research
    -   climate

    -   soils

    -   topography
3.  Limitations of modeling
    -   environmental truncation [@thuiller2004EffectsRestrictingEnvironmental; @hannemann2016DevilDetailUnstable]
4.  Dispersal
5.  Management implications

# Conclusions

# References

::: {#refs}
:::

\newpage

# Appendix A: ODMAP

## Overview

Here we describe the SDMs produced herein following the Overview, Data, Model, Assessment, Prediction (ODMAP) protocol for species distribution models [@zurell2020StandardProtocolReporting]. Here, we first provide the Overview for our modeling, while the remaining ODMAP sections are detailed in Table S\@ref(tab:ODMAP).

The objectives of this modelling exercise are to (1) better explain the drivers of aspen's distribution across the Southern Rocky Mountains, (2) map the area suitable for aspen, and (3) forecast the area suitable for aspen presence in the future under two different climate scenarios.

```{r ODMAP}
pred.var.tab <- read_excel(here("Documents", "ODMAP-Table.xlsx"), sheet=1)

pred.var.tab %>% as.data.frame() %>% flextable()%>% set_caption(caption="ODMAP protocol information. Details on Data, Model, Assessment, Prediction. For Overview section, please refer to main text.") %>% autofit() %>% set_table_properties(layout = "autofit")
```

\newpage

# Appendix B: Collinearity

```{r Screen_Climate_Vars, eval=F}
source(here("Code", "Geom-SplitViolin.R"))
# Import response variable
aspen90.prob <- rast(here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90.tif"))
names(aspen90.prob) <- "aspen.prob"
aspen90.prob01 <- aspen90.prob
aspen90.prob01[aspen90.prob01<0.5]<-0
aspen90.prob01[aspen90.prob01>=0.5]<-1
names(aspen90.prob01) <- "aspen.presence"

writeRaster(aspen90.prob01, here("Data", "Spatial", "Aspen",  "srme_skcv_distribution_binopt-90-presence.tif"), overwrite=T)

SRM <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp")) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs(aspen90.prob))
aspen90.prob <- terra::mask(aspen90.prob, SRM)
aspen90.prob01 <-terra::mask(aspen90.prob01, SRM)

# Import climate variables

climate.dat.1981_2010 <- rast(list.files(here("Data", "Spatial", "Climate", "ClimateNA", "Normal_1981_2010", "Normal_1981_2010_bioclim"), pattern=".tif$", full.names = T))
names(climate.dat.1981_2010) <- sapply(strsplit(do.call(c,strsplit(list.files(here("Data", "Spatial", "Climate", "ClimateNA", "Normal_1981_2010", "Normal_1981_2010_bioclim"), pattern=".tif$", full.names = F), split=".tif")), split="Normal_1981_2010_"), "[", 2)

climate.dat2.1981_2010 <- rast(list.files(here("Data", "Spatial", "Climate", "ClimateNA", "Derived"), pattern="Normal", full.names = T))
names(climate.dat2.1981_2010) <- sapply(strsplit(do.call(c,strsplit(list.files(here("Data", "Spatial", "Climate", "ClimateNA", "Derived"), pattern="Normal", full.names = F), split=".tif")), split="Normal_1981_2010_"), "[",2)


# Compile data
aspen.pts <- aspen90.prob01 %>% as.points(na.rm=T)
aspen.pts <- aspen.pts[sample(1:nrow(aspen.pts), size=50000),]
aspen.pts1 <- aspen.pts %>% filter(aspen.presence==1) %>% sample(size=2500)
aspen.pts0 <- aspen.pts %>% filter(aspen.presence==0) %>% sample(size=2500)
aspen.pts <- rbind(aspen.pts1, aspen.pts0)
aspen.pts <- terra::extract(aspen90.prob,aspen.pts, bind=T, xy=T, cells=T) 
aspen.pts <- aspen.pts %>% terra::project(climate.dat.1981_2010 )

aspen.pts.1981_2010 <- aspen.pts
aspen.pts.1981_2010<- extract(climate.dat.1981_2010, aspen.pts.1981_2010, bind=T)
aspen.pts.1981_2010 <- extract(climate.dat2.1981_2010, aspen.pts.1981_2010, bind=T)
aspen.pts.1981_2010$year <- "1981-2010"

dat <- aspen.pts.1981_2010  %>% as.data.frame() %>% na.omit()
climate.varz <- c("ADI", "bFFP", "CMD", "CMI", "DD_0", "DD_18", "DD1040", "DD18", "DD5", "eFFP", "EMT", "Eref", "EXT", "FFP", "GSP", "GSPDD5", "MAP", "MAR", "MAT","MCMT", "MWMT", "NFFD", "PAS", "PPT_at", "PPT_sm", "PPT_sp", "PPT_wt", "PRATIO", "RH", "Tave_at", "Tave_sm", "Tave_sp", "Tave_wt", "TD", "TMAX")

dat[,c(climate.varz,"year")] %>% filter(year=="1981-2010") %>% select(-year) %>% cor() %>% round(digits=2) %>% write.csv(here("Results", "climate-var-cor.csv"))

dat[,c(sort(climate.varz))] %>% cor() %>% round(digits=2) %>% ggcorrplot(lab=TRUE,type="lower",lab_size=2) %>% ggsave(filename=here("Results", "Figures", "CorrelationMatrix.jpg"), width=210, heigh=210, units="mm")

interactions <- spatialRF::the_feature_engineer(
  data=dat, 
  dependent.variable.name="aspen.presence",
  predictor.variable.names = climate.varz,
  xy=dat[,c("x", "y")],
  importance.threshold = 0.50, #uses 50% best predictors
  cor.threshold = 0.70, #max corr between interactions and predictors
  seed = 123,
  repetitions = 100,
  verbose = FALSE
)

dat.aspen50 <- dat %>% mutate(threshold=">50%")
dat.aspen50$aspen.presence <- factor(ifelse(dat.aspen50$aspen.prob>0.5,"present", "absent"))

dat.aspen75 <- dat %>% mutate(threshold=">75%")
dat.aspen75$aspen.presence <- factor(ifelse(dat.aspen50$aspen.prob>0.5,"present", "absent"))


dat.aspen0 <- dat %>% mutate(threshold=">0%")
dat.aspen0$aspen.presence <- factor(ifelse(dat.aspen50$aspen.prob>0,"present", "absent"))

dat.aspen050 <- rbind(dat.aspen75, dat.aspen50, dat.aspen0)

dat.aspen050 %>% select(all_of(c("aspen.presence", climate.varz, "threshold"))) %>% filter(threshold==">0%") %>% 
  pivot_longer(cols=bFFP:TMAX) %>%
  ggplot(aes(x=threshold, y=value, fill=factor(aspen.presence)))+geom_split_violin()+facet_wrap(~name, scales="free", ncol=6)+theme(legend.position = "bottom", legend.title=element_blank(), axis.title.x=element_blank(), axis.text.x=element_blank())+scale_fill_manual(values=c("gray", "orange")) -> p1
ggsave(p1, filename=here("Results", "Figures", "climate-violin.jpg"), width=180, height=210, units="mm")

rf.dat <- dat
dat_split <- initial_split(
  dat <- dat, 
  prop = 0.5, 
  strata = aspen.presence
)

dat.training <-  training(dat_split)
dat.testing <- testing(dat_split)

results <- data.frame(var=climate.varz, dropout_loss=NA)
for(j in climate.varz){
  datj <- dat %>% select(all_of(c("aspen.presence", j)))
  datj$aspen.presence <- factor(datj$aspen.presence)
  # preprocessing "recipe"
  presence.recipe<- 
    recipe(aspen.presence ~ ., data = datj)  %>%
    # normalize all numeric variables except the outcome and ID variables
    step_normalize(all_numeric(), -all_outcomes())
    
  # Specify model
    rf_spec <- 
      rand_forest() %>%
      set_engine("ranger", importance = "permutation", seed = 123) %>% 
      set_mode("classification")
    
    # Create workflow
    rf_wflow <- 
      workflow() %>% 
      add_recipe(presence.recipe) %>% 
      add_model(rf_spec)

   # Fit model
    rf_fit <- rf_wflow %>% fit(datj)
    
  # Variable importance
explainer_rf <- explain_tidymodels(rf_fit,
                                    data=datj %>%
                                     as.data.frame() %>%
                                     select(-aspen.presence), 
                                    y=datj %>%
                                     pull(aspen.presence) %>%
                                     as.numeric() - 1,
                                    type="classification", verbose=F
)
results[results$var==j, "dropout_loss"] <- explainer_rf  %>% feature_importance(type='ratio') %>% as.data.frame() %>% mutate(Model="RF") %>% filter(variable %in% j) %>% pull(dropout_loss) %>% mean()
}

write.csv(results, here("Results", "bivariate-RF-AUC.csv"),row.names=F)
results <- read.csv(here("Results", "bivariate-RF-AUC.csv"))

results <- results[order(results$dropout_loss),]
levelz <-  results$var
results$var <- factor(results$var, levels=levelz, ordered=T)

results  %>% ggplot( aes(x=var, y=dropout_loss))+geom_bar(stat="identity")+coord_flip()+theme(axis.title.y = element_blank())+ylab("relative importance") ->p1
ggsave(p1, filename=here("Results", "Figures", "climatevarselection-bar.jpg"), width=90, height=120, units="mm")
```

```{r TabClimateScreen}
tab <- read_excel(here("Documents", "PredictorScreeningTable.xlsx"), sheet=1)

tab %>% as.data.frame() %>% flextable() %>% set_caption(caption="Climate variables considered for inclusion in SDMs and modeling notes.") %>% autofit() %>% set_table_properties(layout = "autofit")
```

```{r FigCor, fig.cap="Correlation coefficients between pairs of climate predictor variables examined for inclusion in SDM", out.width = "180mm", out.height="180mm"}
knitr::include_graphics(here("Results/Figures/CorrelationMatrix.jpg"), dpi = NA)
```


# Appendix C: Supplemental figures

<<<<<<< HEAD
```{r MissClassMap, fig.cap="Spatial patterns of missclassification for the ensemble model.", out.width="3.5in", out.height="5in"}
knitr::include_graphics(here("Results", "Figures", "ensemble-error-map.jpg"), dpi = NA)
```

```{r PercentMap, fig.cap="Percent cover", out.width="3.5in", out.height="5in"}
=======

```{r PercentMap, fig.cap="The percent cover of aspen within a 90 x 90 m pixel for the Southern Rocky Mountains. Data were produced by aggregating the 10 m resolution map of aspen presence-absence from Cook et al. (in review).", out.width="3.5in", out.height="5in"}
>>>>>>> master

  aspen90 <-rast(here("Data", "Spatial", "Aspen", "srme_skcv_probability_mosaic-90.tif"))
  aspen90 <- aspen90/10
  
  study.area <- st_read(here("Data", "Spatial", "Ecoregions", "us_eco_l3.shp"), quiet=T) %>% filter(US_L3NAME == 'Southern Rockies') %>% st_transform(crs(aspen90))
  aspen90 <- aspen90 %>%  mask(study.area)
  
  tm.percent <- tm_shape(aspen90)+tm_raster(palette="viridis",title="")+tm_layout(bg.color="white", legend.position = c(0.01,0.825))+tm_shape(study.area) + tm_borders()+ tm_compass( position=c("right", "top"))+ tm_scale_bar(position=c("left", "bottom"))
  Fig.file <- here("Results", "Figures", "aspenpercent-map.jpg") 
  jpeg(Fig.file, width=3.5, height=5, units="in", res=300) 
  tm.percent
  whatever <- dev.off()

knitr::include_graphics(here("Results", "Figures", "aspenpercent-map.jpg"), dpi=NA) 
```


```{r MissClassMap, fig.cap="Spatial patterns of missclassification for the ensemble model.", out.width="3.5in", out.height="5in"}
knitr::include_graphics(here("Results", "Figures", "ensemble-error-map.jpg"), dpi = NA)
```

```{r FutureChange, fig.cap="The ensemble projection of aspen habitat suitability under current conditions and projections for future periods based on the projected climate for the SSP5-8.5 scenario."}
knitr::include_graphics(here("Results", "Figures", "FigMaps-Change.jpg"), dpi=NA)
```

```{r LossGainMaps, fig.cap="The distribution of pixels where the ensemble SDM forecasts aspen may be lost, gained, or stable by 2100 under the SSP2-4.5 scenario.", out.width="3.5in", out.height="5in"}
knitr::include_graphics(here("Results", "Figures", "FigMaps-LossGain1.jpg"), dpi = NA)
```

```{r GainDistanceMaps, fig.cap="Distance to the nearest existing aspen patch for pixels were future climate may promote aspen expansion by 2100.", out.width="3.5in", out.height="3.25in"}
knitr::include_graphics(here("Results", "Figures", "FigMaps-Gain-Distance1.jpg"), dpi = NA)
```

